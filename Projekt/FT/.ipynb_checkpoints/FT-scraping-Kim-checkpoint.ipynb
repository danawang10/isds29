{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2755d5bf",
   "metadata": {},
   "source": [
    "# Scraping af FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdacc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re \n",
    "import os\n",
    "import lxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import objectify\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import requests\n",
    "import ftplib\n",
    "from io import BytesIO\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ab18d",
   "metadata": {},
   "source": [
    "##### Tomme lister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a743493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = []\n",
    "sub_dir = []\n",
    "files = []\n",
    "file_name = []\n",
    "paths = []\n",
    "raw_xml_list = []\n",
    "\n",
    "suppe = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71dc66",
   "metadata": {},
   "source": [
    "### Login til ftp serveren og henter en liste over biblioteker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd2856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_url = \"oda.ft.dk\"\n",
    "ftp_dir = \"/ODAXML/Referat/samling/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ee869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp = ftplib.FTP(ftp_url)\n",
    "ftp.login(\"anonymous\", \"wpg345@alumni.ku.dk\")\n",
    "ftp.set_pasv(True)\n",
    "ftp.cwd(ftp_dir)\n",
    "ftp.dir(dirs.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c846be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(dirs), 1):    # bygger en liste med underbiblioteker\n",
    "    sub_dir.append(ftp_dir+dirs[i][-5:]+'/') \n",
    "    \n",
    "for i in range (0, len(sub_dir), 1): # bygger en liste med filnavne\n",
    "    ftp.cwd(sub_dir[i])\n",
    "    ftp.dir(files.append)\n",
    "\n",
    "for i in range(0, len(files)):       # extract filnavn\n",
    "    file_name.append(files[i][39:])   \n",
    "\n",
    "for i in range(0, len(file_name)):   # opbygning af den fulde sti og filnavn\n",
    "    paths.append(ftp_dir+file_name[i][0:5]+'/'+file_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33938698",
   "metadata": {},
   "source": [
    "### Overførsel af de enkelte filer fra ftp://oda.ft.dk, og raw_xml skrives til liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c822719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1489/1489 [04:39<00:00,  5.34it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(0, len(paths))):\n",
    "    r = BytesIO()\n",
    "    ftp.retrbinary(f\"RETR {paths[i]}\", r.write)\n",
    "    raw_xml_list.append(r.getvalue())\n",
    "    r.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879466f1",
   "metadata": {},
   "source": [
    "# Define path function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e88e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_path VIRKER\n",
    "repeats = []\n",
    "\n",
    "def extract_path(xml_list):\n",
    "    \n",
    "    for xml in xml_list: \n",
    "        soup = bs(xml, 'lxml')\n",
    "        repeats.append(len(soup.find_all(\"dagsordenpunkt\")))\n",
    "    \n",
    "    for i in range(0, len(xml_list)): \n",
    "        p = paths[i]\n",
    "        path.extend([p] * repeats[i]) \n",
    "        #extend acts as append but multiplied by n times\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940a5d2",
   "metadata": {},
   "source": [
    "Bemærk vi er interesseret i len(xml_list) modsat de næste funktioner, hvor det ikke behøver spille nogen rolle. Derfor vælger vi ikke at integrere extract_path ind i extract_metadata. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9d674",
   "metadata": {},
   "source": [
    "# Define metadata function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69938dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vers1 virker\n",
    "def extract_metadata(xml):\n",
    "    soup = bs(xml, 'lxml')\n",
    "    \n",
    "    d = soup.find(\"dateofsitting\").text[:10]\n",
    "    m = soup.find(\"meetingnumber\").text\n",
    "    s = soup.find(\"parliamentarysession\").text\n",
    "    g = soup.find(\"parliamentarygroup\").text\n",
    "    l = soup.find(\"location\").text\n",
    "    \n",
    "    # antal gange de samme metadata gentages for hvert dagordenpunkt\n",
    "    repeats = len(soup.find_all(\"dagsordenpunkt\")) \n",
    "    \n",
    "    for repeat in range(0, repeats):\n",
    "        date.append(d)\n",
    "        meetingnumber.append(m)\n",
    "        session.append(s)\n",
    "        group.append(g)\n",
    "        location.append(l)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d444d942",
   "metadata": {},
   "source": [
    "# Define content function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc788acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(xml): \n",
    "    soup = bs(xml, 'lxml')\n",
    "    dagsordenpunkter = soup.find_all(\"dagsordenpunkt\") # liste med dagsordenpunkter\n",
    "    #print(f\"Antal dagsordenpunkter: {len(dagsordenpunkter)}\")\n",
    "    \n",
    "    for dp in dagsordenpunkter: # find raw xml-sætninger for hvert dagsordenpunkt\n",
    "        sentences_raw = dp.find_all(\"linea\") # liste med raw sætninger \n",
    "        #print(f\"Antal sentences_raw: {len(sentences_raw)}\")\n",
    "        \n",
    "        sentences_text = []\n",
    "        \n",
    "        for sr in sentences_raw: # for hver raw sætning, kør .text af sætningen\n",
    "            sentences_text.append(sr.get_text(separator = ' ')) # gem clean sætninger til liste\n",
    "        \n",
    "        content.append(' '.join(sentences_text).strip()) # join, strip og append clean sætninger til liste\n",
    "        #print(f\"Antal content: {len(content)}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a587a0",
   "metadata": {},
   "source": [
    "# Test of ftitemtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d96d4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ftcasetype(xml): \n",
    "    soup = bs(xml, 'lxml')\n",
    "    dagsordenpunkter = soup.find_all(\"dagsordenpunkt\") # liste med dagsordenpunkter\n",
    "    #print(f\"Antal dagsordenpunkter: {len(dagsordenpunkter)}\")\n",
    "    \n",
    "    for dp in dagsordenpunkter: # find raw xml-sætninger for hvert dagsordenpunkt\n",
    "        ftcasetype_raw = dp.find_all(\"ftcasetype\") # liste med raw sætninger \n",
    "        print(ftcasetype_raw)\n",
    "        #print(f\"Antal sentences_raw: {len(sentences_raw)}\")\n",
    "        \n",
    "        ftcasetype = []\n",
    "        \n",
    "        for sr in ftcasetype_raw: # for hver raw sætning, kør .text af sætningen\n",
    "            ftcasetype.append(sr.get_text(separator = ' ')) # gem clean sætninger til liste\n",
    "            print(ftcasetype)\n",
    "        ftcasetype.append(ftcasetype) # join, strip og append clean sætninger til liste\n",
    "        #print(f\"Antal content: {len(content)}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03da44d",
   "metadata": {},
   "source": [
    "# Sample run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7ecd9c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xml_sample = raw_xml_list[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61d78d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ftcasetype>FM</ftcasetype>]\n",
      "['FM']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>FM</ftcasetype>]\n",
      "['FM']\n"
     ]
    }
   ],
   "source": [
    "for xml in xml_sample: \n",
    "    extract_ftcasetype(xml) # FTCaseType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c8c0b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftcasetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a092296e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "for xml in tqdm.tqdm(xml_sample): \n",
    "    extract_content(xml) # content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98f72116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for xml in tqdm.tqdm(xml_sample): \n",
    "    extract_content(xml) # content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91a0dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Meddelelser fra formanden Tredje næstformand  (Holger K. Nielsen) Mødet er åbnet. Finansudvalget har afgivet: Betænkning og indstilling vedrørende forslag til folketingsbeslutning i henhold til grundlovens § 47 med hensyn til statsregnskabet for finansåret 2008. (Beslutningsforslag nr. B 248). Betænkningen og indstillingen vil fremgå af www.folketingstidende.dk.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae9c68d4",
   "metadata": {},
   "source": [
    "# Full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3b62df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists (columns)\n",
    "date = []\n",
    "content = []\n",
    "meetingnumber = []\n",
    "session = []\n",
    "group = []\n",
    "location = []\n",
    "titel = [] # aktivitet\n",
    "path = []\n",
    "ftcasetype = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d87c6a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1489/1489 [12:33<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for xml in tqdm.tqdm(raw_xml_list): \n",
    "    extract_metadata(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c38929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1489/1489 [13:11<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for xml in tqdm.tqdm(raw_xml_list): \n",
    "    extract_content(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "518de4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████▊                     | 1085/1489 [09:08<03:24,  1.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mextract_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_xml_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mextract_path\u001b[1;34m(xml_list)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_path\u001b[39m(xml_list):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m xml \u001b[38;5;129;01min\u001b[39;00m xml_list: \n\u001b[1;32m----> 7\u001b[0m         soup \u001b[38;5;241m=\u001b[39m \u001b[43mbs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         repeats\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdagsordenpunkt\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(xml_list)): \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\builder\\_lxml.py:378\u001b[0m, in \u001b[0;36mLXMLTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser_for(encoding)\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m, \u001b[38;5;167;01mLookupError\u001b[39;00m, etree\u001b[38;5;241m.\u001b[39mParserError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32msrc/lxml/parser.pxi:1256\u001b[0m, in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/lxml/parser.pxi:1376\u001b[0m, in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/lxml/parsertarget.pxi:168\u001b[0m, in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/lxml/parsertarget.pxi:156\u001b[0m, in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/lxml/etree.pyx:333\u001b[0m, in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/lxml/saxparser.pxi:443\u001b[0m, in \u001b[0;36mlxml.etree._handleSaxTargetStartNoNs\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/lxml/saxparser.pxi:458\u001b[0m, in \u001b[0;36mlxml.etree._callTargetSaxStart\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/lxml/parsertarget.pxi:94\u001b[0m, in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\builder\\_lxml.py:243\u001b[0m, in \u001b[0;36mLXMLTreeBuilderForXML.start\u001b[1;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsmaps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_NSMAPS_INVERTED]\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, attrs, nsmap\u001b[38;5;241m=\u001b[39m{}):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# Make sure attrs is a mutable dict--lxml may send an immutable dictproxy.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(attrs)\n\u001b[0;32m    246\u001b[0m     nsprefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extract_path(tqdm.tqdm(raw_xml_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f918cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_ftcasetype(tqdm.tqdm(raw_xml_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58f2b5c",
   "metadata": {},
   "source": [
    "### title kladdder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c95795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = bs(sample1, 'lxml')\n",
    "test = soup.find(\"punkttekst\").find_all(\"char\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = raw_xml_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b600c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample1 = raw_xml_list[0]\n",
    "soup = bs(sample1, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ae909",
   "metadata": {},
   "source": [
    "# Make DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452c96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([date, content, meetingnumber, session, group, location, path, ftitemtype]).transpose()\n",
    "df.columns = ['date', 'content', 'meetingnumber', 'session', 'group', 'location', 'path', 'ftitemtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f9da1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac1249",
   "metadata": {},
   "source": [
    "# Examining the empty content rows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff8d2df",
   "metadata": {},
   "source": [
    "# Save df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d668a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('FT.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b171ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6b2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08e10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a12175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
