{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2755d5bf",
   "metadata": {},
   "source": [
    "# Scraping af FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdacc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re \n",
    "import os\n",
    "import lxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import objectify\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import requests\n",
    "import ftplib\n",
    "from io import BytesIO\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ab18d",
   "metadata": {},
   "source": [
    "##### Tomme lister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a743493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = []\n",
    "sub_dir = []\n",
    "files = []\n",
    "file_name = []\n",
    "paths = []\n",
    "raw_xml_list = []\n",
    "\n",
    "suppe = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71dc66",
   "metadata": {},
   "source": [
    "### Login til ftp serveren og henter en liste over biblioteker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd2856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_url = \"oda.ft.dk\"\n",
    "ftp_dir = \"/ODAXML/Referat/samling/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ee869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp = ftplib.FTP(ftp_url)\n",
    "ftp.login(\"anonymous\", \"wpg345@alumni.ku.dk\")\n",
    "ftp.set_pasv(True)\n",
    "ftp.cwd(ftp_dir)\n",
    "ftp.dir(dirs.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c846be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(dirs), 1):    # bygger en liste med underbiblioteker\n",
    "    sub_dir.append(ftp_dir+dirs[i][-5:]+'/') \n",
    "    \n",
    "for i in range (0, len(sub_dir), 1): # bygger en liste med filnavne\n",
    "    ftp.cwd(sub_dir[i])\n",
    "    ftp.dir(files.append)\n",
    "\n",
    "for i in range(0, len(files)):       # extract filnavn\n",
    "    file_name.append(files[i][39:])   \n",
    "\n",
    "for i in range(0, len(file_name)):   # opbygning af den fulde sti og filnavn\n",
    "    paths.append(ftp_dir+file_name[i][0:5]+'/'+file_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33938698",
   "metadata": {},
   "source": [
    "### Overførsel af de enkelte filer fra ftp://oda.ft.dk, og raw_xml skrives til liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c822719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1489/1489 [04:39<00:00,  5.34it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(0, len(paths))):\n",
    "    r = BytesIO()\n",
    "    ftp.retrbinary(f\"RETR {paths[i]}\", r.write)\n",
    "    raw_xml_list.append(r.getvalue())\n",
    "    r.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879466f1",
   "metadata": {},
   "source": [
    "# Define path function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e88e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_path VIRKER\n",
    "repeats = []\n",
    "\n",
    "def extract_path(xml_list):\n",
    "    \n",
    "    for xml in xml_list: \n",
    "        soup = bs(xml, 'lxml')\n",
    "        repeats.append(len(soup.find_all(\"dagsordenpunkt\")))\n",
    "    \n",
    "    for i in range(0, len(xml_list)): \n",
    "        p = paths[i]\n",
    "        path.extend([p] * repeats[i]) \n",
    "        #extend acts as append but multiplied by n times\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940a5d2",
   "metadata": {},
   "source": [
    "Bemærk vi er interesseret i len(xml_list) modsat de næste funktioner, hvor det ikke behøver spille nogen rolle. Derfor vælger vi ikke at integrere extract_path ind i extract_metadata. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9d674",
   "metadata": {},
   "source": [
    "# Define metadata function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69938dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vers1 virker\n",
    "def extract_metadata(xml):\n",
    "    soup = bs(xml, 'lxml')\n",
    "    \n",
    "    d = soup.find(\"dateofsitting\").text[:10]\n",
    "    m = soup.find(\"meetingnumber\").text\n",
    "    s = soup.find(\"parliamentarysession\").text\n",
    "    g = soup.find(\"parliamentarygroup\").text\n",
    "    l = soup.find(\"location\").text\n",
    "    \n",
    "    # antal gange de samme metadata gentages for hvert dagordenpunkt\n",
    "    repeats = len(soup.find_all(\"dagsordenpunkt\")) \n",
    "    \n",
    "    for repeat in range(0, repeats):\n",
    "        date.append(d)\n",
    "        meetingnumber.append(m)\n",
    "        session.append(s)\n",
    "        group.append(g)\n",
    "        location.append(l)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d444d942",
   "metadata": {},
   "source": [
    "# Define content function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc788acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(xml): \n",
    "    soup = bs(xml, 'lxml')\n",
    "    dagsordenpunkter = soup.find_all(\"dagsordenpunkt\") # liste med dagsordenpunkter\n",
    "    #print(f\"Antal dagsordenpunkter: {len(dagsordenpunkter)}\")\n",
    "    \n",
    "    for dp in dagsordenpunkter: # find raw xml-sætninger for hvert dagsordenpunkt\n",
    "        sentences_raw = dp.find_all(\"linea\") # liste med raw sætninger \n",
    "        #print(f\"Antal sentences_raw: {len(sentences_raw)}\")\n",
    "        \n",
    "        sentences_text = []\n",
    "        \n",
    "        for sr in sentences_raw: # for hver raw sætning, kør .text af sætningen\n",
    "            sentences_text.append(sr.get_text(separator = ' ')) # gem clean sætninger til liste\n",
    "        \n",
    "        content.append(' '.join(sentences_text).strip()) # join, strip og append clean sætninger til liste\n",
    "        #print(f\"Antal content: {len(content)}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48560b3d",
   "metadata": {},
   "source": [
    "# Test of ftitemtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "760cd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ftcasetype(xml): \n",
    "    soup = bs(xml, 'lxml')\n",
    "    dagsordenpunkter = soup.find_all(\"dagsordenpunkt\") # liste med dagsordenpunkter\n",
    "    #print(f\"Antal dagsordenpunkter: {len(dagsordenpunkter)}\")\n",
    "    \n",
    "    for dp in dagsordenpunkter: # find raw xml-sætninger for hvert dagsordenpunkt\n",
    "        ftcasetype_raw = dp.find_all(\"ftcasetype\") # liste med raw sætninger \n",
    "        print(ftcasetype_raw)\n",
    "        #print(f\"Antal sentences_raw: {len(sentences_raw)}\")\n",
    "        \n",
    "        ftcasetype = []\n",
    "        \n",
    "        for sr in ftcasetype_raw: # for hver raw sætning, kør .text af sætningen\n",
    "            ftcasetype.append(sr.get_text(separator = ' ')) # gem clean sætninger til liste\n",
    "            print(ftcasetype)\n",
    "        ftcasetype.append(ftcasetype) # join, strip og append clean sætninger til liste\n",
    "        #print(f\"Antal content: {len(content)}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03da44d",
   "metadata": {},
   "source": [
    "# Sample run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7ecd9c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xml_sample = raw_xml_list[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61d78d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ftcasetype>FM</ftcasetype>]\n",
      "['FM']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>L</ftcasetype>]\n",
      "['L']\n",
      "[<ftcasetype>FM</ftcasetype>]\n",
      "['FM']\n"
     ]
    }
   ],
   "source": [
    "for xml in xml_sample: \n",
    "    extract_ftcasetype(xml) # FTCaseType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0d0116b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftcasetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "815cefa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "for xml in tqdm.tqdm(xml_sample): \n",
    "    extract_content(xml) # content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98f72116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for xml in tqdm.tqdm(xml_sample): \n",
    "    extract_content(xml) # content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91a0dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Meddelelser fra formanden Tredje næstformand  (Holger K. Nielsen) Mødet er åbnet. Finansudvalget har afgivet: Betænkning og indstilling vedrørende forslag til folketingsbeslutning i henhold til grundlovens § 47 med hensyn til statsregnskabet for finansåret 2008. (Beslutningsforslag nr. B 248). Betænkningen og indstillingen vil fremgå af www.folketingstidende.dk.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae9c68d4",
   "metadata": {},
   "source": [
    "# Full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3b62df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists (columns)\n",
    "date = []\n",
    "content = []\n",
    "meetingnumber = []\n",
    "session = []\n",
    "group = []\n",
    "location = []\n",
    "titel = [] # aktivitet\n",
    "path = []\n",
    "ftcasetype = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d87c6a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1489/1489 [12:33<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for xml in tqdm.tqdm(raw_xml_list): \n",
    "    extract_metadata(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c38929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1489/1489 [13:11<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for xml in tqdm.tqdm(raw_xml_list): \n",
    "    extract_content(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518de4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████                                              | 623/1489 [05:02<08:31,  1.69it/s]"
     ]
    }
   ],
   "source": [
    "extract_path(tqdm.tqdm(raw_xml_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe8be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_ftcasetype(tqdm.tqdm(raw_xml_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58f2b5c",
   "metadata": {},
   "source": [
    "### title kladdder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c95795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = bs(sample1, 'lxml')\n",
    "test = soup.find(\"punkttekst\").find_all(\"char\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = raw_xml_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b600c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample1 = raw_xml_list[0]\n",
    "soup = bs(sample1, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ae909",
   "metadata": {},
   "source": [
    "# Make DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452c96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([date, content, meetingnumber, session, group, location, path, ftitemtype]).transpose()\n",
    "df.columns = ['date', 'content', 'meetingnumber', 'session', 'group', 'location', 'path', 'ftitemtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f9da1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac1249",
   "metadata": {},
   "source": [
    "# Examining the empty content rows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff8d2df",
   "metadata": {},
   "source": [
    "# Save df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d668a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('FT.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b171ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6b2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08e10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a12175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
