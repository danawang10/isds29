{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79730dd1",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "104a18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import lemmy # For lemmatization\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "import itertools\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625421b1",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c7efcb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_sygeplej2x = pd.read_csv('ft_sygeplej2x.csv')\n",
    "dr_sygeplej2x = pd.read_csv('dr_sygeplej2x.csv')\n",
    "tv2_sygeplej2x = pd.read_csv('tv2_sygeplej2x.csv')\n",
    "\n",
    "ft_2 = ft_sygeplej2x.copy() \n",
    "dr_2 = dr_sygeplej2x.copy() \n",
    "tv2_2 = tv2_sygeplej2x.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc6d86",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20156b7c",
   "metadata": {},
   "source": [
    "## Remove non-alphanumerical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cddac7b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgb569\\AppData\\Local\\Temp/ipykernel_17052/1145022020.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['content'] = df['content'].str.replace(r'\\W', ' ')\\\n"
     ]
    }
   ],
   "source": [
    "for df in [ft_2, dr_2, tv2_2]:\n",
    "    df['content'] = df['content'].str.replace(r'\\W', ' ')\\\n",
    "                                 .str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ab60a",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd50b7d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jgb569\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download tokenizer\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ad3dac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_2['tokenized'] = dr_2.apply(lambda row: nltk.tokenize.word_tokenize(row[\"content\"]), axis = 1)\n",
    "tv2_2['tokenized'] = tv2_2.apply(lambda row: nltk.tokenize.word_tokenize(row[\"content\"]), axis = 1)\n",
    "ft_2['tokenized'] = ft_2.apply(lambda row: nltk.tokenize.word_tokenize(row[\"content\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e21993",
   "metadata": {},
   "source": [
    "### Stemming of entire wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "feecd5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"danish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ccf75599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentences(document):\n",
    "    non_alpha = re.sub(r'[^\\w\\s]', '', document)\n",
    "    tokens = non_alpha.split()\n",
    "    stemmed_tokens=[stemmer.stem(word) for word in tokens] # all words in a list\n",
    "    no_stop = [word for word in stemmed_tokens if not word in stopwords]\n",
    "    stems=' '.join(no_stop)\n",
    "    stems_no_num = re.sub(r'[^\\D+]', '', stems)\n",
    "    return stems_no_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379bcd09",
   "metadata": {},
   "source": [
    "#### Bag  of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "83caf13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stem_col(df):\n",
    "    df_stemmed_list=[]\n",
    "    for row in tqdm.tqdm(df['content']):\n",
    "        stems=stem_sentences(row)\n",
    "        df_stemmed_list.append(stems)\n",
    "    df['stems'] = df_stemmed_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8dd29577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 528/528 [00:03<00:00, 147.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3607/3607 [00:32<00:00, 111.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 296/296 [01:37<00:00,  3.03it/s]\n"
     ]
    }
   ],
   "source": [
    "dr_analysis = add_stem_col(dr_2)\n",
    "tv2_analysis = add_stem_col(tv2_2)\n",
    "ft_analysis = add_stem_col(ft_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8f85f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoW(df): \n",
    "    count = CountVectorizer()\n",
    "    df_array = df['stems']\n",
    "    bag = count.fit_transform(df_array)\n",
    "    \n",
    "    count_array = bag.toarray() #Make the bag to an array\n",
    "    matrix = pd.DataFrame(data=count_array,columns = count.get_feature_names())\n",
    "    matrix_sum = matrix.sum().transpose()\n",
    "    matrix_sum.sort_values(ascending = False, inplace = True)\n",
    "    return matrix_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bf849b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_bow = BoW(dr_analysis)\n",
    "tv2_bow = BoW(tv2_analysis)\n",
    "ft_bow = BoW(ft_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b37ded16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvilk               112\n",
       "lær                 110\n",
       "mindr               110\n",
       "virk                109\n",
       "stud                109\n",
       "nyhed               108\n",
       "stig                107\n",
       "praktis             106\n",
       "stilling            106\n",
       "dår                 105\n",
       "faktisk             104\n",
       "nødt                103\n",
       "netop               103\n",
       "job                 102\n",
       "selvfølg            102\n",
       "ansæt               102\n",
       "faggrup             101\n",
       "nej                 101\n",
       "vurd                101\n",
       "sker                101\n",
       "følg                101\n",
       "gjort               101\n",
       "altså               100\n",
       "måsk                 99\n",
       "stad                 98\n",
       "forsøg               98\n",
       "milliard             96\n",
       "arbejdsmiljø         95\n",
       "klart                95\n",
       "handl                95\n",
       "vej                  95\n",
       "privat               95\n",
       "uger                 95\n",
       "mennesk              94\n",
       "ansvar               94\n",
       "stil                 94\n",
       "haft                 93\n",
       "begynd               91\n",
       "understreg           91\n",
       "enkelt               91\n",
       "tænk                 91\n",
       "fokus                91\n",
       "valg                 91\n",
       "konsekvens           90\n",
       "forhandling          89\n",
       "aalborg              88\n",
       "midtjylland          88\n",
       "stør                 88\n",
       "næstformand          88\n",
       "kræv                 87\n",
       "især                 87\n",
       "nødvend              86\n",
       "opmærksom            86\n",
       "kollega              86\n",
       "ræk                  86\n",
       "sagt                 85\n",
       "glad                 85\n",
       "sundhedspersonal     85\n",
       "uge                  85\n",
       "såkald               85\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_bow[200:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5a194feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = BoW(dr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bcff499e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sygeplejersk            2969\n",
       "ikk                     2533\n",
       "kan                     1905\n",
       "så                      1531\n",
       "patient                 1328\n",
       "                        ... \n",
       "næstsidst                  1\n",
       "diskussionsspørgsmål       1\n",
       "dispensation               1\n",
       "nærpolitistation           1\n",
       "lægevagtplanlægning        1\n",
       "Length: 9194, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d1c04a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix_sum.to_csv(\"dr_word_frequency.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ff7f1",
   "metadata": {},
   "source": [
    "#### TV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4cfbd5c8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/1349431805.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstemmed_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtv2_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mstems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstem_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mstemmed_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/3528421427.py\u001b[0m in \u001b[0;36mstem_sentences\u001b[1;34m(document)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnon_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_alpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mstemmed_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# all words in a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mno_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstemmed_tokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_stop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/3528421427.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnon_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_alpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mstemmed_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# all words in a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mno_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstemmed_tokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_stop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\snowball.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;31m# STEP 4: Undouble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdouble_cons\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__double_consonants\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdouble_cons\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m                 \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stemmed_list=[]\n",
    "for i in tv2_2['content']:\n",
    "    stems=stem_sentences(i)\n",
    "    stemmed_list.append(stems)\n",
    "\n",
    "tv2_2['stems']=stemmed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3a4b0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer() #Store the class in 'count' to ease coding\n",
    "count_array = tv2_2['stems'] #Take the first two reviews and store them in an array\n",
    "bag = count.fit_transform(count_array) #fit_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cc7c57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = bag.toarray() #Make the bag to an array\n",
    "matrix = pd.DataFrame(data=array,columns = count.get_feature_names()) #Input the bag and the words into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1d8e5671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_sum = matrix.sum().transpose()\n",
    "matrix_sum.sort_values(ascending = False)\n",
    "matrix_sum.to_csv(\"tv2_word_frequency.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6f798",
   "metadata": {},
   "source": [
    "#### Folketinget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fdeb425d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 296/296 [01:50<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "stemmed_list=[]\n",
    "for i in tqdm.tqdm(ft_2['content']):\n",
    "    stems=stem_sentences(i)\n",
    "    stemmed_list.append(stems)\n",
    "\n",
    "ft_2['stems']=stemmed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9f8a602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer() #Store the class in 'count' to ease coding\n",
    "count_array = ft_2['stems'] #Take the first two reviews and store them in an array\n",
    "bag = count.fit_transform(count_array) #fit_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fb374b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = bag.toarray() #Make the bag to an array\n",
    "matrix = pd.DataFrame(data=array,columns = count.get_feature_names()) #Input the bag and the words into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "48bcf342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ikk                               98174\n",
       "så                                82428\n",
       "kan                               63835\n",
       "vær                               45419\n",
       "kom                               30076\n",
       "                                  ...  \n",
       "landedokumentationskontor             1\n",
       "landdistriktsvækstpilotordning        1\n",
       "landdistriktsudspil                   1\n",
       "landdistriktssegment                  1\n",
       "øvsag                                 1\n",
       "Length: 45808, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sum = matrix.sum().transpose()\n",
    "matrix_sum.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9027ec",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5d36da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(df):\n",
    "    ############################## bag #################################\n",
    "    count = CountVectorizer() #Choose only 2-grams\n",
    "    \n",
    "    df_array = df['stems']\n",
    "    bag = count.fit_transform(df_array)\n",
    "    ############################## bag #################################\n",
    "    \n",
    "    tfidf = TfidfTransformer()\n",
    "    bag_tfidf = tfidf.fit_transform(bag) \n",
    "\n",
    "    tfidf_array = bag_tfidf.toarray() #Make the bag to an array\n",
    "    matrix_tfidf = pd.DataFrame(data=tfidf_array,columns = count.get_feature_names())\n",
    "    return matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0b664b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = tfidf(dr_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5a438bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aabenraa</th>\n",
       "      <th>aag</th>\n",
       "      <th>aagaard</th>\n",
       "      <th>aahaug</th>\n",
       "      <th>aaholm</th>\n",
       "      <th>aalborg</th>\n",
       "      <th>aarhus</th>\n",
       "      <th>aarhusiansk</th>\n",
       "      <th>aaskov</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>østjylland</th>\n",
       "      <th>østjysk</th>\n",
       "      <th>østkyst</th>\n",
       "      <th>østr</th>\n",
       "      <th>øve</th>\n",
       "      <th>øvels</th>\n",
       "      <th>øver</th>\n",
       "      <th>øverst</th>\n",
       "      <th>øvet</th>\n",
       "      <th>øvr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528 rows × 9194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aabenraa  aag  aagaard  aahaug  aaholm   aalborg  aarhus  aarhusiansk  \\\n",
       "0         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "1         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "2         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "3         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "4         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "..        ...  ...      ...     ...     ...       ...     ...          ...   \n",
       "523       0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "524       0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "525       0.0  0.0      0.0     0.0     0.0  0.034848     0.0          0.0   \n",
       "526       0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "527       0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "\n",
       "     aaskov  abc  ...  østjylland  østjysk  østkyst  østr  øve  øvels  øver  \\\n",
       "0       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "1       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "2       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "3       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "4       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "..      ...  ...  ...         ...      ...      ...   ...  ...    ...   ...   \n",
       "523     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "524     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "525     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "526     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "527     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "\n",
       "     øverst  øvet  øvr  \n",
       "0       0.0   0.0  0.0  \n",
       "1       0.0   0.0  0.0  \n",
       "2       0.0   0.0  0.0  \n",
       "3       0.0   0.0  0.0  \n",
       "4       0.0   0.0  0.0  \n",
       "..      ...   ...  ...  \n",
       "523     0.0   0.0  0.0  \n",
       "524     0.0   0.0  0.0  \n",
       "525     0.0   0.0  0.0  \n",
       "526     0.0   0.0  0.0  \n",
       "527     0.0   0.0  0.0  \n",
       "\n",
       "[528 rows x 9194 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b09beaf",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2bf02a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jgb569\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get stopwords list\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('danish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ac957",
   "metadata": {},
   "source": [
    "### Tokenized content for three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9023eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords from token-list\n",
    "dr_nostop = [word for word in dr_2_tokens if not word in stopwords]\n",
    "tv2_nostop = [word for word in tv2_2_tokens if not word in stopwords]\n",
    "ft_nostop = [word for word in ft_2_tokens if not word in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f983164",
   "metadata": {},
   "source": [
    "### Create set of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22997c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_complete = dr_nostop + tv2_nostop + ft_nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baaf30d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['antallet',\n",
       " 'danske',\n",
       " 'sygeplejersker',\n",
       " 'fået',\n",
       " 'autorisation',\n",
       " 'norge',\n",
       " 'næsten',\n",
       " 'tredoblet',\n",
       " 'år',\n",
       " 'krise',\n",
       " 'fyringer',\n",
       " 'ansættelsesstop',\n",
       " 'får',\n",
       " 'sygeplejerskerne',\n",
       " 'tage',\n",
       " 'norge',\n",
       " 'arbejde',\n",
       " 'sygeplejersker',\n",
       " 'brænder',\n",
       " 'fag',\n",
       " 'helt',\n",
       " 'naturligt',\n",
       " 'søger',\n",
       " 'derhen',\n",
       " 'arbejde',\n",
       " 'desværre',\n",
       " 'situation',\n",
       " 'danmark',\n",
       " 'arbejdsgiverne',\n",
       " 'valgt',\n",
       " 'ansætte',\n",
       " 'kompetente',\n",
       " 'sygeplejersker',\n",
       " 'bekymrende',\n",
       " 'siger',\n",
       " 'grete',\n",
       " 'christensen',\n",
       " 'formand',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'seneste',\n",
       " 'tal',\n",
       " 'viser',\n",
       " 'antallet',\n",
       " 'danske',\n",
       " 'sygeplejersker',\n",
       " 'fået',\n",
       " 'autorisation',\n",
       " 'norge',\n",
       " 'steget',\n",
       " '154',\n",
       " 'januar',\n",
       " '2010',\n",
       " '434',\n",
       " 'januar',\n",
       " '2011',\n",
       " 'helt',\n",
       " 'afgørende',\n",
       " 'herhjemme',\n",
       " 'får',\n",
       " 'gjort',\n",
       " 'muligt',\n",
       " 'tilbyde',\n",
       " 'vores',\n",
       " 'sygeplejersker',\n",
       " 'job',\n",
       " 'kommuner',\n",
       " 'regionerne',\n",
       " 'siger',\n",
       " 'grete',\n",
       " 'christensen',\n",
       " 'trods',\n",
       " 'fyringsrunder',\n",
       " 'sygehusene',\n",
       " 'både',\n",
       " '2010',\n",
       " '2011',\n",
       " 'nedlæggelse',\n",
       " 'sygehuse',\n",
       " 'faxe',\n",
       " 'nakskov',\n",
       " 'kalundborg',\n",
       " 'så',\n",
       " 'få',\n",
       " 'arbejdsløse',\n",
       " 'sygeplejersker',\n",
       " 'region',\n",
       " 'sjælland',\n",
       " 'seneste',\n",
       " 'tal',\n",
       " 'viser',\n",
       " '85',\n",
       " 'ledige',\n",
       " 'arbejdsløsheds',\n",
       " 'procent',\n",
       " 'ca',\n",
       " 'kredsformand',\n",
       " 'helle',\n",
       " 'dirksen',\n",
       " 'tvivl',\n",
       " 'ledige',\n",
       " 'simpelthen',\n",
       " 'rejst',\n",
       " 'andre',\n",
       " 'steder',\n",
       " 'hen',\n",
       " 'mener',\n",
       " 'sygeplejerskerne',\n",
       " 'protesterede',\n",
       " 'voldsomt',\n",
       " 'fyringsrunderne',\n",
       " 'kan',\n",
       " 'godt',\n",
       " 'se',\n",
       " 'andre',\n",
       " 'faggrupper',\n",
       " 'hårdere',\n",
       " 'ramt',\n",
       " 'vores',\n",
       " 'bekymring',\n",
       " 'gik',\n",
       " 'især',\n",
       " 'nyuddannede',\n",
       " 'svært',\n",
       " 'ved',\n",
       " 'finmde',\n",
       " 'fodfæste',\n",
       " 'arbejdsmarkedet',\n",
       " 'siger',\n",
       " 'helle',\n",
       " 'dirksen',\n",
       " 'knap',\n",
       " 'halvdelen',\n",
       " '85',\n",
       " 'ledige',\n",
       " 'november',\n",
       " 'nyuddannede',\n",
       " 'februar',\n",
       " 'nyt',\n",
       " 'hold',\n",
       " 'sygeplejersker',\n",
       " 'færdige',\n",
       " 'sygeplejeskolerne',\n",
       " 'undskylde',\n",
       " 'beklage',\n",
       " 'formanden',\n",
       " 'region',\n",
       " 'sjælland',\n",
       " 'steen',\n",
       " 'bach',\n",
       " 'nielsen',\n",
       " 'tænkt',\n",
       " 'opfylde',\n",
       " 'kravet',\n",
       " 'offentlig',\n",
       " 'undskyldning',\n",
       " 'ansatte',\n",
       " 'sygehuset',\n",
       " 'nykøbing',\n",
       " 'falster',\n",
       " 'dermed',\n",
       " 'spidser',\n",
       " 'striden',\n",
       " 'mellem',\n",
       " 'socialdemokratiske',\n",
       " 'regionsformand',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'rådet',\n",
       " 'truer',\n",
       " 'anmelde',\n",
       " 'steen',\n",
       " 'bach',\n",
       " 'nielsen',\n",
       " 'ombudsmanden',\n",
       " 'krænkelse',\n",
       " 'offentligt',\n",
       " 'ansattes',\n",
       " 'ytringsfrihed',\n",
       " 'fordi',\n",
       " 'sagen',\n",
       " 'overdødelighed',\n",
       " 'sygehuset',\n",
       " 'nykøbing',\n",
       " 'falster',\n",
       " 'stærkt',\n",
       " 'opfordrede',\n",
       " 'lokalt',\n",
       " 'ansatte',\n",
       " 'sygeplejersker',\n",
       " 'samarbejde',\n",
       " 'stedet',\n",
       " 'diskutere',\n",
       " 'via',\n",
       " 'peressen',\n",
       " 'regionsformanden',\n",
       " 'kan',\n",
       " 'forstå',\n",
       " 'sygeplejerskerne',\n",
       " 'opfattet',\n",
       " 'lade',\n",
       " 'ytre',\n",
       " 'kritik',\n",
       " 'offentlige',\n",
       " 'kan',\n",
       " 'sige',\n",
       " 'undskyld',\n",
       " 'fordi',\n",
       " 'gerne',\n",
       " 'dialog',\n",
       " 'mener',\n",
       " 'steen',\n",
       " 'bach',\n",
       " 'nielsen',\n",
       " 'aftalt',\n",
       " 'møde',\n",
       " 'onsdag',\n",
       " 'formiddagmellem',\n",
       " 'region',\n",
       " 'sjælland',\n",
       " 'ogdansk',\n",
       " 'sygeplejeråd',\n",
       " 'kredsformand',\n",
       " 'helle',\n",
       " 'dirksen',\n",
       " 'siger',\n",
       " 'inden',\n",
       " 'mødet',\n",
       " 'dsr',\n",
       " 'står',\n",
       " 'fast',\n",
       " 'kravet',\n",
       " 'offentlig',\n",
       " 'undskyldning',\n",
       " 'beklagelse',\n",
       " 'overfor',\n",
       " 'fællestillidsmanden',\n",
       " 'sygeplejerskerne',\n",
       " 'nykøbing',\n",
       " 'falster',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'repræsenterer',\n",
       " 'landets',\n",
       " 'omkring',\n",
       " '70',\n",
       " '000',\n",
       " 'sygeplejersker',\n",
       " 'mener',\n",
       " 'muligt',\n",
       " 'medarbejdere',\n",
       " 'kun',\n",
       " 'tage',\n",
       " 'højst',\n",
       " 'to',\n",
       " 'nattevagter',\n",
       " 'træk',\n",
       " 'meldingen',\n",
       " 'kommer',\n",
       " 'baggrund',\n",
       " 'anbefalinger',\n",
       " 'danske',\n",
       " 'internationale',\n",
       " 'eksperter',\n",
       " 'hvordan',\n",
       " 'forebygger',\n",
       " 'brystkræft',\n",
       " 'ved',\n",
       " 'natarbejde',\n",
       " 'blandt',\n",
       " 'rådene',\n",
       " 'hurtigt',\n",
       " 'roterende',\n",
       " 'vagtskift',\n",
       " 'kun',\n",
       " 'to',\n",
       " 'hinanden',\n",
       " 'følgende',\n",
       " 'nattevagter',\n",
       " 'fremfor',\n",
       " 'tre',\n",
       " 'flere',\n",
       " 'nattevagter',\n",
       " 'træk',\n",
       " 'rigtig',\n",
       " 'godt',\n",
       " 'eksperterne',\n",
       " 'kommer',\n",
       " 'konkrete',\n",
       " 'anbefalinger',\n",
       " 'højst',\n",
       " 'to',\n",
       " 'nattevagter',\n",
       " 'træk',\n",
       " 'øjne',\n",
       " 'klareste',\n",
       " 'anbefaling',\n",
       " 'siger',\n",
       " 'dorte',\n",
       " 'steenberg',\n",
       " 'næstformand',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'fortsætter',\n",
       " 'går',\n",
       " 'arbejdsgiverne',\n",
       " 'tage',\n",
       " 'ansvar',\n",
       " 'sørge',\n",
       " 'muligt',\n",
       " 'medarbejderne',\n",
       " 'følge',\n",
       " 'eksperternes',\n",
       " 'råd',\n",
       " 'helt',\n",
       " 'nødvendigt',\n",
       " 'sygeplejersker',\n",
       " 'arbejder',\n",
       " 'natten',\n",
       " 'tager',\n",
       " 'patienter',\n",
       " 'undersøgelser',\n",
       " 'vist',\n",
       " 'klar',\n",
       " 'sammenhæng',\n",
       " 'mellem',\n",
       " 'brystkræft',\n",
       " 'natarbejde',\n",
       " 'så',\n",
       " 'forpligtelse',\n",
       " 'gøre',\n",
       " 'kan',\n",
       " 'forebygge',\n",
       " 'medarbejdere',\n",
       " 'syge',\n",
       " 'siger',\n",
       " 'ekspertanbefaling',\n",
       " 'tilrettelægge',\n",
       " 'arbejdet',\n",
       " 'uret',\n",
       " 'så',\n",
       " 'ens',\n",
       " 'vagter',\n",
       " 'går',\n",
       " 'dag',\n",
       " 'aften',\n",
       " 'aften',\n",
       " 'nat',\n",
       " 'nat',\n",
       " 'dag',\n",
       " 'ifølge',\n",
       " 'undersøgelser',\n",
       " 'giver',\n",
       " 'mindre',\n",
       " 'forstyrrelse',\n",
       " 'døgnrytmen',\n",
       " 'døgnrytmen',\n",
       " 'hele',\n",
       " 'tiden',\n",
       " 'udfordret',\n",
       " 'så',\n",
       " 'stresser',\n",
       " 'kroppen',\n",
       " 'kan',\n",
       " 'negativ',\n",
       " 'effekt',\n",
       " 'derfor',\n",
       " 'helt',\n",
       " 'afgørende',\n",
       " 'sørger',\n",
       " 'lave',\n",
       " 'vagtplaner',\n",
       " 'følger',\n",
       " 'uret',\n",
       " 'så',\n",
       " 'mindst',\n",
       " 'muligt',\n",
       " 'pres',\n",
       " 'forløbene',\n",
       " 'mere',\n",
       " 'naturlige',\n",
       " 'siger',\n",
       " 'dorte',\n",
       " 'steenberg',\n",
       " 'ritzau',\n",
       " 'slut',\n",
       " 'sygeplejerudtryk',\n",
       " 'gebrokkent',\n",
       " 'dansk',\n",
       " 'nordjyske',\n",
       " 'sygehuse',\n",
       " 'få',\n",
       " 'år',\n",
       " 'siden',\n",
       " 'måtte',\n",
       " 'sygehusene',\n",
       " 'importere',\n",
       " 'sygeplejersker',\n",
       " 'tyskland',\n",
       " 'siden',\n",
       " 'besparelser',\n",
       " 'betydet',\n",
       " 'ledige',\n",
       " 'danske',\n",
       " 'sygeplejersker',\n",
       " 'så',\n",
       " 'længere',\n",
       " 'bruge',\n",
       " 'hente',\n",
       " 'sygeplejersker',\n",
       " 'andre',\n",
       " 'lande',\n",
       " 'øjeblikket',\n",
       " 'ingen',\n",
       " 'interesse',\n",
       " 'rekruttere',\n",
       " 'udenlandske',\n",
       " 'sygeplejersker',\n",
       " 'fortæller',\n",
       " 'jytte',\n",
       " 'wester',\n",
       " 'formand',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'nordjylland',\n",
       " 'tilbage',\n",
       " '2008',\n",
       " 'håndtere',\n",
       " 'region',\n",
       " 'nordjylland',\n",
       " 'lavede',\n",
       " 'aftale',\n",
       " 'mere',\n",
       " '40',\n",
       " 'tyske',\n",
       " 'sygeplejersker',\n",
       " 'fordi',\n",
       " 'manglede',\n",
       " 'arbejdskraft',\n",
       " 'dag',\n",
       " 'må',\n",
       " 'jytte',\n",
       " 'wester',\n",
       " 'stedet',\n",
       " 'guide',\n",
       " 'medlemmer',\n",
       " 'kan',\n",
       " 'få',\n",
       " 'arbejde',\n",
       " 'øjeblikket',\n",
       " 'værste',\n",
       " 'situation',\n",
       " 'haft',\n",
       " 'år',\n",
       " 'arbejdsløse',\n",
       " 'sygeplejersker',\n",
       " 'kø',\n",
       " 'vokser',\n",
       " 'vokser',\n",
       " 'siger',\n",
       " 'gang',\n",
       " 'brugte',\n",
       " 'regionen',\n",
       " 'penge',\n",
       " 'lære',\n",
       " 'udenlandske',\n",
       " 'sygeplejersker',\n",
       " 'dansk',\n",
       " 'integrere',\n",
       " 'nødvendighed',\n",
       " 'mener',\n",
       " 'jytte',\n",
       " 'wester',\n",
       " 'hjælp',\n",
       " 'få',\n",
       " 'tilstrækkelig',\n",
       " 'arbejdskraft',\n",
       " 'gjorde',\n",
       " 'indsats',\n",
       " 'få',\n",
       " 'tilstrækkeligt',\n",
       " 'sygeplejersker',\n",
       " 'siger',\n",
       " 'sygeplejersker',\n",
       " 'stor',\n",
       " 'stil',\n",
       " 'uddannet',\n",
       " 'ledighed',\n",
       " '85',\n",
       " 'procent',\n",
       " 'nyuddannede',\n",
       " 'sygeplejersker',\n",
       " 'uddannelserne',\n",
       " 'viborg',\n",
       " 'holstebro',\n",
       " 'arbejdsløse',\n",
       " 'så',\n",
       " 'går',\n",
       " 'tre',\n",
       " 'halvt',\n",
       " 'år',\n",
       " 'su',\n",
       " 'ogstudie',\n",
       " 'så',\n",
       " 'kommer',\n",
       " 'arbejdsmarked',\n",
       " 'arbejde',\n",
       " 'få',\n",
       " 'siger',\n",
       " 'anita',\n",
       " 'staarup',\n",
       " 'nyuddannede',\n",
       " 'sygeplejersker',\n",
       " 'nyuddannede',\n",
       " 'holstebro',\n",
       " 'kommer',\n",
       " 'arbejdsløshed',\n",
       " 'mens',\n",
       " 'kun',\n",
       " 'syv',\n",
       " 'sygeplejersker',\n",
       " 'uddannelsen',\n",
       " 'viborg',\n",
       " 'job',\n",
       " 'seneste',\n",
       " 'halve',\n",
       " 'års',\n",
       " 'tid',\n",
       " '200',\n",
       " 'sygeplejersker',\n",
       " 'blevet',\n",
       " 'fyret',\n",
       " 'ved',\n",
       " 'hospitalsenheden',\n",
       " 'vest',\n",
       " 'sygehuset',\n",
       " 'viborg',\n",
       " 'giver',\n",
       " 'endnu',\n",
       " 'ringere',\n",
       " 'chancer',\n",
       " 'lyder',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'grund',\n",
       " 'store',\n",
       " 'besparelser',\n",
       " 'igennem',\n",
       " 'region',\n",
       " 'midtjylland',\n",
       " 'så',\n",
       " 'kommet',\n",
       " 'del',\n",
       " 'ledige',\n",
       " 'sygeplejersker',\n",
       " 'samtidig',\n",
       " 'nyuddannede',\n",
       " 'svært',\n",
       " 'ved',\n",
       " 'få',\n",
       " 'job',\n",
       " 'siger',\n",
       " 'bente',\n",
       " 'rasmussen',\n",
       " 'næstformand',\n",
       " 'sygeplejerskerne',\n",
       " 'region',\n",
       " 'midtjylland',\n",
       " 'betyder',\n",
       " 'sygeplejersker',\n",
       " 'søger',\n",
       " 'udlandet',\n",
       " 'eksempel',\n",
       " 'norge',\n",
       " 'arbejde',\n",
       " 'få',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'region',\n",
       " 'midtjylland',\n",
       " 'holder',\n",
       " 'jobmesse',\n",
       " '6',\n",
       " 'marts',\n",
       " 'mulighed',\n",
       " 'høre',\n",
       " 'ledige',\n",
       " 'stillinger',\n",
       " 'norge',\n",
       " 'viborg',\n",
       " 'kommune',\n",
       " 'kører',\n",
       " 'projekt',\n",
       " 'jobrotation',\n",
       " 'sygeplejersker',\n",
       " 'arbejder',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'starte',\n",
       " 'holstebro',\n",
       " 'området',\n",
       " 'lige',\n",
       " '237',\n",
       " 'ledige',\n",
       " 'sygeplejersker',\n",
       " 'region',\n",
       " 'midtjylland',\n",
       " 'nyuddannede',\n",
       " 'sygeplejersker',\n",
       " 'svært',\n",
       " 'ved',\n",
       " 'finde',\n",
       " 'arbejde',\n",
       " '17',\n",
       " 'procent',\n",
       " 'nyuddannede',\n",
       " 'sidste',\n",
       " 'sommers',\n",
       " 'hold',\n",
       " 'trillet',\n",
       " 'tommelfingre',\n",
       " 'lang',\n",
       " 'tid',\n",
       " 'syddanmark',\n",
       " 'billedet',\n",
       " 'lidt',\n",
       " 'mere',\n",
       " 'positivt',\n",
       " 'glæder',\n",
       " 'formanden',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'syddanmark',\n",
       " 'john',\n",
       " 'christiansen',\n",
       " 'primære',\n",
       " 'forklaring',\n",
       " 'især',\n",
       " 'sygehusområdet',\n",
       " 'indset',\n",
       " 'vigtigt',\n",
       " 'lidt',\n",
       " 'højere',\n",
       " 'normering',\n",
       " 'bruge',\n",
       " 'eksterne',\n",
       " 'vikarer',\n",
       " 'så',\n",
       " 'betyder',\n",
       " 'fastansat',\n",
       " 'lidt',\n",
       " 'flere',\n",
       " 'sygeplejerske',\n",
       " 'sygehusområdet',\n",
       " 'tidligere',\n",
       " 'siger',\n",
       " 'hurtigere',\n",
       " 'adgang',\n",
       " 'arbejdsmarkedet',\n",
       " 'ifølge',\n",
       " 'sygeplejerskenes',\n",
       " 'formand',\n",
       " 'vigtigt',\n",
       " 'få',\n",
       " 'god',\n",
       " 'start',\n",
       " 'faget',\n",
       " 'gør',\n",
       " 'rodfæstes',\n",
       " 'hurtigere',\n",
       " 'enkelte',\n",
       " 'sygeplejerske',\n",
       " 'betyder',\n",
       " 'bedre',\n",
       " 'kan',\n",
       " 'etablere',\n",
       " 'private',\n",
       " 'liv',\n",
       " 'betyder',\n",
       " 'sandsynligheden',\n",
       " 'indenfor',\n",
       " 'sygeplejerskefaget',\n",
       " 'større',\n",
       " 'siger',\n",
       " 'john',\n",
       " 'christiansen',\n",
       " 'blevet',\n",
       " 'sværere',\n",
       " 'nyuddannede',\n",
       " 'sygeplejersker',\n",
       " 'finde',\n",
       " 'job',\n",
       " 'ledigheden',\n",
       " 'landsplan',\n",
       " 'steget',\n",
       " '2',\n",
       " '17',\n",
       " 'procent',\n",
       " 'menhvis',\n",
       " 'heldet',\n",
       " 'overveje',\n",
       " 'flytte',\n",
       " 'region',\n",
       " 'syddanmark',\n",
       " 'nemlig',\n",
       " 'størst',\n",
       " 'chance',\n",
       " 'ansat',\n",
       " 'formand',\n",
       " 'sygeplejerådet',\n",
       " 'syddanmark',\n",
       " 'john',\n",
       " 'christiansen',\n",
       " 'tror',\n",
       " 'skyldes',\n",
       " 'ændret',\n",
       " 'forhold',\n",
       " 'mellem',\n",
       " 'vikarer',\n",
       " 'fastansatte',\n",
       " 'især',\n",
       " 'sygehusområdet',\n",
       " 'indset',\n",
       " 'deter',\n",
       " 'vigtigt',\n",
       " 'lidt',\n",
       " 'højere',\n",
       " 'nomering',\n",
       " 'bruge',\n",
       " 'eksterne',\n",
       " 'vikarer',\n",
       " 'betyder',\n",
       " 'manhar',\n",
       " 'ansat',\n",
       " 'lidt',\n",
       " 'flere',\n",
       " 'sygeplejerskerpå',\n",
       " 'sygehusområdet',\n",
       " 'tidligere',\n",
       " 'hanmener',\n",
       " 'hurtige',\n",
       " 'adgang',\n",
       " 'arbejdsmarkedet',\n",
       " 'vigtig',\n",
       " 'sygeplejerskerne',\n",
       " 'kommer',\n",
       " 'godt',\n",
       " 'faget',\n",
       " 'rodfæstes',\n",
       " 'langt',\n",
       " 'hurtigere',\n",
       " 'helt',\n",
       " 'personligt',\n",
       " 'enkelte',\n",
       " 'sygeplejerske',\n",
       " 'gør',\n",
       " 'selvfølgelig',\n",
       " 'bedre',\n",
       " 'kan',\n",
       " 'etablere',\n",
       " 'private',\n",
       " 'liv',\n",
       " 'kan',\n",
       " 'huskøb',\n",
       " 'ellerdet',\n",
       " 'få',\n",
       " 'børn',\n",
       " 'betyder',\n",
       " 'sandsynligheden',\n",
       " 'så',\n",
       " 'inden',\n",
       " 'sygeplejerskefaget',\n",
       " 'større',\n",
       " 'siger',\n",
       " 'john',\n",
       " 'christiansen',\n",
       " 'http',\n",
       " 'mu',\n",
       " 'net',\n",
       " 'dr',\n",
       " 'dk',\n",
       " 'admin',\n",
       " 'programcard',\n",
       " 'get',\n",
       " 'id',\n",
       " 'urn',\n",
       " 'dr',\n",
       " 'mu',\n",
       " 'programcard',\n",
       " '54f47a6f6187a411cc6fcdb0http',\n",
       " 'mu',\n",
       " 'net',\n",
       " 'dr',\n",
       " 'dk',\n",
       " 'admin',\n",
       " 'programcard',\n",
       " 'get',\n",
       " 'id',\n",
       " 'urn',\n",
       " 'dr',\n",
       " 'mu',\n",
       " 'programcard',\n",
       " '550949d96187a912fce98132',\n",
       " 'nye',\n",
       " 'akutlinje',\n",
       " 'region',\n",
       " 'hovedstaden',\n",
       " 'specialuddannede',\n",
       " 'sygeplejersker',\n",
       " 'står',\n",
       " 'klar',\n",
       " 'rådgive',\n",
       " 'får',\n",
       " 'hug',\n",
       " 'lægeforeningen',\n",
       " 'skriver',\n",
       " 'ugeskrift',\n",
       " 'læger',\n",
       " 'region',\n",
       " 'hovedstaden',\n",
       " 'råder',\n",
       " 'stort',\n",
       " 'antal',\n",
       " 'vagtlæger',\n",
       " 'eksperter',\n",
       " 'burde',\n",
       " 'overlade',\n",
       " 'rent',\n",
       " 'faktisk',\n",
       " 'kan',\n",
       " 'lave',\n",
       " 'slags',\n",
       " 'opgaver',\n",
       " 'udføre',\n",
       " 'siger',\n",
       " 'lægeforeningens',\n",
       " 'formand',\n",
       " 'mads',\n",
       " 'koch',\n",
       " 'hansen',\n",
       " 'ugeskrift',\n",
       " 'læger',\n",
       " 'kan',\n",
       " 'både',\n",
       " 'stille',\n",
       " 'diagnose',\n",
       " 'fortælle',\n",
       " 'præcist',\n",
       " 'patienten',\n",
       " 'gå',\n",
       " 'hen',\n",
       " 'videre',\n",
       " 'systemet',\n",
       " 'hvorfor',\n",
       " 'starte',\n",
       " 'lægen',\n",
       " 'gør',\n",
       " 'andre',\n",
       " 'steder',\n",
       " 'synes',\n",
       " 'tilbud',\n",
       " 'overflødigt',\n",
       " 'må',\n",
       " 'forvirre',\n",
       " 'patienten',\n",
       " 'siger',\n",
       " 'akuttelefonen',\n",
       " '1813',\n",
       " 'startede',\n",
       " '30',\n",
       " 'januar',\n",
       " 'specialuddannet',\n",
       " 'sygeplejerske',\n",
       " 'modtager',\n",
       " 'opkald',\n",
       " 'døgnet',\n",
       " 'rundt',\n",
       " 'henviser',\n",
       " 'yderligere',\n",
       " 'behandling',\n",
       " 'vurderer',\n",
       " 'nødvendigt',\n",
       " 'snit',\n",
       " '600',\n",
       " 'opkald',\n",
       " 'døgnet',\n",
       " 'direktør',\n",
       " 'akutberedskabet',\n",
       " 'region',\n",
       " 'hovedstaden',\n",
       " 'freddy',\n",
       " 'lippert',\n",
       " 'forstår',\n",
       " 'kritikken',\n",
       " 'ønsker',\n",
       " 'dels',\n",
       " 'aflaste',\n",
       " 'vores',\n",
       " 'akutmodtagelser',\n",
       " 'dels',\n",
       " 'hjælpe',\n",
       " 'borgerne',\n",
       " 'let',\n",
       " 'adgang',\n",
       " 'relevante',\n",
       " 'behandling',\n",
       " 'derfor',\n",
       " 'samlet',\n",
       " 'tilbud',\n",
       " 'sted',\n",
       " 'fagfolk',\n",
       " 'sidder',\n",
       " 'klar',\n",
       " '24',\n",
       " 'timer',\n",
       " 'døgnet',\n",
       " 'forklarer',\n",
       " 'borgeren',\n",
       " 'søge',\n",
       " 'hjælp',\n",
       " '112',\n",
       " 'akutte',\n",
       " 'livstruende',\n",
       " 'hændelser',\n",
       " '1813',\n",
       " 'døgntilbud',\n",
       " 'borgerne',\n",
       " 'siger',\n",
       " 'samtidig',\n",
       " 'kritiserer',\n",
       " 'forbrugerrådet',\n",
       " 'måde',\n",
       " 'regionen',\n",
       " 'reklameret',\n",
       " 'akutlinjen',\n",
       " 'grænsen',\n",
       " 'lovlige',\n",
       " 'sundhedsstyrelsen',\n",
       " 'sætter',\n",
       " 'forbrugerrådet',\n",
       " 'plads',\n",
       " 'sagen',\n",
       " 'nye',\n",
       " 'akutlinje',\n",
       " '1813',\n",
       " 'region',\n",
       " 'hovedstaden',\n",
       " 'sidder',\n",
       " 'specialudannede',\n",
       " 'sygeplejersker',\n",
       " 'klar',\n",
       " 'ved',\n",
       " 'telefonen',\n",
       " 'rådgive',\n",
       " 'borgere',\n",
       " 'søger',\n",
       " 'sundhedsfaglige',\n",
       " 'råd',\n",
       " 'vejledning',\n",
       " 'lægeforeningen',\n",
       " 'ude',\n",
       " 'akutlinjen',\n",
       " 'mener',\n",
       " 'forvirrer',\n",
       " 'patienterne',\n",
       " 'desuden',\n",
       " 'forbrugerrådet',\n",
       " 'kritiseret',\n",
       " 'region',\n",
       " 'hovedstadens',\n",
       " 'reklamer',\n",
       " 'mener',\n",
       " 'kant',\n",
       " 'loven',\n",
       " 'henvist',\n",
       " 'forbudt',\n",
       " 'andre',\n",
       " 'læger',\n",
       " 'stille',\n",
       " 'diagnoser',\n",
       " 'påstand',\n",
       " 'maner',\n",
       " 'sundhedsstyrelsen',\n",
       " 'jorden',\n",
       " 'forbeholdt',\n",
       " 'nogen',\n",
       " 'helst',\n",
       " 'stille',\n",
       " 'diagnoser',\n",
       " 'siger',\n",
       " 'anne',\n",
       " 'mette',\n",
       " 'dons',\n",
       " 'chef',\n",
       " 'tilsyn',\n",
       " 'patientsikkerhed',\n",
       " 'sundhedsstyrelsen',\n",
       " 'dsr',\n",
       " 'dk',\n",
       " 'står',\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "578cce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5356096"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d87406",
   "metadata": {},
   "source": [
    "The total number of words across our three datasets is 5356096."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abb33c",
   "metadata": {},
   "source": [
    "Our unique wordset contains 115189 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd261a2a",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f151b",
   "metadata": {},
   "source": [
    "### Stemming of content by source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cd8b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sourcestemmer(wordlist):\n",
    "    wordlist_stemmed = [stemmer.stem(word) for word in wordlist]\n",
    "    return wordlist_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b825e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_stemmed = sourcestemmer(dr_nostop)\n",
    "tv2_stemmed = sourcestemmer(tv2_nostop)\n",
    "ft_stemmed = sourcestemmer(ft_nostop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3843fc",
   "metadata": {},
   "source": [
    "### Wordcount for complete content of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c495cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting lists together to one large string as preprocessing for wordcount\n",
    "dr_string = \" \".join(dr_stemmed)\n",
    "tv2_string = \" \".join(tv2_stemmed)\n",
    "ft_string = \" \".join(ft_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ad6cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a5e09",
   "metadata": {},
   "source": [
    "#### DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50fb0ada",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.96 GiB for an array with shape (125596, 9574) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/2318576253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Make the bag to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Input the bag and the words into a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmatrix_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmatrix_sum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.96 GiB for an array with shape (125596, 9574) and data type int64"
     ]
    }
   ],
   "source": [
    "#Store the class in 'count' to ease coding\n",
    "dr_bag = count.fit_transform(dr_stemmed) #fit_transform takes an array as input and outputs the bag of words\n",
    "\n",
    "dr_count_array = dr_bag.toarray() #Make the bag to an array\n",
    "dr_matrix = pd.DataFrame(data=dr_count_array,columns = count.get_feature_names_out()) #Input the bag and the words into a dataframe\n",
    "dr_matrix_sum = dr_matrix.sum().transpose()\n",
    "dr_matrix_sum.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef6b6a18",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'list_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/2305459028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'os' has no attribute 'list_dir'"
     ]
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b7cfe",
   "metadata": {},
   "source": [
    "#### TV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f94ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the class in 'count' to ease coding\n",
    "tv2_bag = count.fit_transform(tv2_stemmed) #fit_transform takes an array as input and outputs the bag of words\n",
    "\n",
    "tv2_array = tv2_bag.toarray() #Make the bag to an array\n",
    "tv2_matrix = pd.DataFrame(data=tv2_array,columns = count.get_feature_names_out()) #Input the bag and the words into a dataframe\n",
    "tv2_matrix_sum = tv2_matrix.sum().transpose()\n",
    "tv2_matrix_sum.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4a9dd",
   "metadata": {},
   "source": [
    "#### Folketinget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c284773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the class in 'count' to ease coding\n",
    "ft_bag = count.fit_transform(ft_stemmed) #fit_transform takes an array as input and outputs the bag of words\n",
    "\n",
    "ft_count_array = ft_bag.toarray() #Make the bag to an array\n",
    "ft_matrix = pd.DataFrame(data=ft_count_array,columns = count.get_feature_names_out()) #Input the bag and the words into a dataframe\n",
    "ft_matrix_sum = ft_matrix.sum().transpose()\n",
    "ft_matrix_sum.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44768ca",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6babeda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Danish lemmatizer\n",
    "lem = lemmy.load(\"da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a932ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_lem = [lem.lemmatize(\"\", word) for word in wordset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0dce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list instead of list of list\n",
    "wordlist_lem = [word for sublist in wordlist_lem for word in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde72845",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_lem_2 = wordlist_lem_2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae373299",
   "metadata": {},
   "source": [
    "Comment: The lemmatization returns a list of lists that also contains more than two words which could lead to problems.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d349ea",
   "metadata": {},
   "source": [
    "## Stemming and bag of words for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd983f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1e56891",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9d3e36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(text,n):\n",
    "    '''Searches for text, and retrieves n words either side of the text, which are retuned seperatly'''\n",
    "    word = r\"\\W*([\\w]+)t\"\n",
    "    groups = re.search(r'{}\\W*{}{}'.format(word*n,'sygeplejersker',word*n), text).group()\n",
    "    return groups[:n],groups[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2eea0257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 37.18it/s]\n"
     ]
    }
   ],
   "source": [
    "relevant_list=[]\n",
    "for row in tqdm.tqdm(dr_2['content'][0:10]):\n",
    "    relevant_list.append(search(row, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f9e17a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      antallet af danske sygeplejersker der har fået...\n",
       "1      trods fyringsrunder på sygehusene i både 2010 ...\n",
       "2      der er ikke noget at undskylde eller beklage  ...\n",
       "3      dansk sygeplejeråd der repræsenterer landets o...\n",
       "4      det er slut med sygeplejerudtryk på gebrokkent...\n",
       "                             ...                        \n",
       "523    det er ikke kun sygeplejersker der flygter fra...\n",
       "524     patienter ligger på gangene og dør fordi de i...\n",
       "525    højere løn og bedre arbejdstider det var det s...\n",
       "526    meldingen fra sundhedsmyndighederne har været ...\n",
       "527    det var et ønske om at se sine børn noget mere...\n",
       "Name: content, Length: 528, dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da76715",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. split auf leerzeichen, jedes wort element\n",
    "2. Finde wort in index. Index position. \n",
    "3. Position + 10 und -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6851272",
   "metadata": {},
   "outputs": [],
   "source": [
    "findallcan be anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cc5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = re.compile(pattern)\n",
    "result = prog.match(string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
