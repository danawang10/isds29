{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3e0775",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bd701edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import lemmy # For lemmatization\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "import itertools\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa819e",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a843fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_sygeplej2x = pd.read_csv('ft_sygeplej2x.csv')\n",
    "dr_sygeplej2x = pd.read_csv('dr_sygeplej2x.csv')\n",
    "tv2_sygeplej2x = pd.read_csv('tv2_sygeplej2x.csv')\n",
    "\n",
    "ft_2 = ft_sygeplej2x.copy() \n",
    "dr_2 = dr_sygeplej2x.copy() \n",
    "tv2_2 = tv2_sygeplej2x.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee43c4",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136fdca",
   "metadata": {},
   "source": [
    "## Remove non-alphanumerical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f9b7c005",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgb569\\AppData\\Local\\Temp/ipykernel_17052/1145022020.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['content'] = df['content'].str.replace(r'\\W', ' ')\\\n"
     ]
    }
   ],
   "source": [
    "for df in [ft_2, dr_2, tv2_2]:\n",
    "    df['content'] = df['content'].str.replace(r'\\W', ' ')\\\n",
    "                                 .str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430cbbb",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "722f0d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jgb569\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download tokenizer\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "44d4289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_2['tokenized'] = dr_2.apply(lambda row: nltk.tokenize.word_tokenize(row[\"content\"]), axis = 1)\n",
    "tv2_2['tokenized'] = tv2_2.apply(lambda row: nltk.tokenize.word_tokenize(row[\"content\"]), axis = 1)\n",
    "ft_2['tokenized'] = ft_2.apply(lambda row: nltk.tokenize.word_tokenize(row[\"content\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60161591",
   "metadata": {},
   "source": [
    "### Stemming of entire wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "015763e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"danish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "49b4d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentences(document):\n",
    "    non_alpha = re.sub(r'[^\\w\\s]', '', document)\n",
    "    tokens = non_alpha.split()\n",
    "    stemmed_tokens=[stemmer.stem(word) for word in tokens] # all words in a list\n",
    "    no_stop = [word for word in stemmed_tokens if not word in stopwords]\n",
    "    stems=' '.join(no_stop)\n",
    "    stems_no_num = re.sub(r'[^\\D+]', '', stems)\n",
    "    return stems_no_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66e6c6",
   "metadata": {},
   "source": [
    "### Bag  of words - Wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "00777f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stem_col(df):\n",
    "    df_stemmed_list=[]\n",
    "    for row in tqdm.tqdm(df['content']):\n",
    "        stems=stem_sentences(row)\n",
    "        df_stemmed_list.append(stems)\n",
    "    df['stems'] = df_stemmed_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c6cf8b19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 528/528 [00:03<00:00, 147.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3607/3607 [00:32<00:00, 111.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 296/296 [01:37<00:00,  3.03it/s]\n"
     ]
    }
   ],
   "source": [
    "dr_analysis = add_stem_col(dr_2)\n",
    "tv2_analysis = add_stem_col(tv2_2)\n",
    "ft_analysis = add_stem_col(ft_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0e456db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoW(df): \n",
    "    count = CountVectorizer()\n",
    "    df_array = df['stems']\n",
    "    bag = count.fit_transform(df_array)\n",
    "    \n",
    "    count_array = bag.toarray() #Make the bag to an array\n",
    "    matrix = pd.DataFrame(data=count_array,columns = count.get_feature_names())\n",
    "    matrix_sum = matrix.sum().transpose()\n",
    "    matrix_sum.sort_values(ascending = False, inplace = True)\n",
    "    return matrix_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6b5adfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoW_relevant(df): \n",
    "    count = CountVectorizer()\n",
    "    df_array = df['relevant']\n",
    "    bag = count.fit_transform(df_array)\n",
    "    \n",
    "    count_array = bag.toarray() #Make the bag to an array\n",
    "    matrix = pd.DataFrame(data=count_array,columns = count.get_feature_names())\n",
    "    matrix_sum = matrix.sum().transpose()\n",
    "    matrix_sum.sort_values(ascending = False, inplace = True)\n",
    "    return matrix_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "52f8f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_bow = BoW(dr_analysis)\n",
    "tv2_bow = BoW(tv2_analysis)\n",
    "ft_bow = BoW(ft_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9116f6d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvilk               112\n",
       "lær                 110\n",
       "mindr               110\n",
       "virk                109\n",
       "stud                109\n",
       "nyhed               108\n",
       "stig                107\n",
       "praktis             106\n",
       "stilling            106\n",
       "dår                 105\n",
       "faktisk             104\n",
       "nødt                103\n",
       "netop               103\n",
       "job                 102\n",
       "selvfølg            102\n",
       "ansæt               102\n",
       "faggrup             101\n",
       "nej                 101\n",
       "vurd                101\n",
       "sker                101\n",
       "følg                101\n",
       "gjort               101\n",
       "altså               100\n",
       "måsk                 99\n",
       "stad                 98\n",
       "forsøg               98\n",
       "milliard             96\n",
       "arbejdsmiljø         95\n",
       "klart                95\n",
       "handl                95\n",
       "vej                  95\n",
       "privat               95\n",
       "uger                 95\n",
       "mennesk              94\n",
       "ansvar               94\n",
       "stil                 94\n",
       "haft                 93\n",
       "begynd               91\n",
       "understreg           91\n",
       "enkelt               91\n",
       "tænk                 91\n",
       "fokus                91\n",
       "valg                 91\n",
       "konsekvens           90\n",
       "forhandling          89\n",
       "aalborg              88\n",
       "midtjylland          88\n",
       "stør                 88\n",
       "næstformand          88\n",
       "kræv                 87\n",
       "især                 87\n",
       "nødvend              86\n",
       "opmærksom            86\n",
       "kollega              86\n",
       "ræk                  86\n",
       "sagt                 85\n",
       "glad                 85\n",
       "sundhedspersonal     85\n",
       "uge                  85\n",
       "såkald               85\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_bow[200:260]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f4643",
   "metadata": {},
   "source": [
    "### Wordcount with relevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4b44fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_surround_words2(text, keyword, n):\n",
    "    '''\n",
    "    text : input text\n",
    "    keyword : the search keyword we are looking\n",
    "    n : number of words around the keyword\n",
    "    '''\n",
    "    surround_words=[]\n",
    "    #extracting all the words from text\n",
    "    words = words = re.findall(r'\\w+', text)\n",
    "    \n",
    "    #iterate through all the words\n",
    "    for index, word in enumerate(words):\n",
    "\n",
    "        #check if search keyword matches\n",
    "        if word == keyword:\n",
    "            #fetch left side words\n",
    "            left_side_words = words[index-n : index]\n",
    "            \n",
    "            #fetch right side words\n",
    "            right_side_words = words[index+1 : index + n + 1]\n",
    "            \n",
    "            surround_words.append(left_side_words)\n",
    "            surround_words.append(right_side_words)\n",
    "    return surround_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d6999767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant(df, word, n):\n",
    "    r=[]\n",
    "    for row in df['stems']:\n",
    "        temp=extract_surround_words2(row, word, n)\n",
    "        temp_list=[]\n",
    "        for i in temp:\n",
    "            stems=' '.join(i)\n",
    "            temp_list.append(stems)\n",
    "            s=\" \".join(temp_list)\n",
    "        r.append(s)\n",
    "    df['relevant']=r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "20ee3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_relevant5 = find_relevant(dr_2, \"sygeplejersk\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2e2ba8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_relevant_bow5 = BoW_relevant(dr_relevant5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "99b7bca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ikk             330\n",
       "læg             259\n",
       "fler            257\n",
       "kan             243\n",
       "arbejd          199\n",
       "så              179\n",
       "vær             163\n",
       "dansk           154\n",
       "strejk          144\n",
       "bliv            139\n",
       "mang            136\n",
       "sygeplejersk    114\n",
       "kom             114\n",
       "region          114\n",
       "patient         111\n",
       "bland            96\n",
       "år               96\n",
       "and              95\n",
       "ell              95\n",
       "land             88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_relevant_bow5[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f6ea9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_relevant1 = find_relevant(dr_2, \"sygeplejersk\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b02dc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_relevant_bow1 = BoW_relevant(dr_relevant1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9b046d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "læg             232\n",
       "fler            221\n",
       "ikk             211\n",
       "kan             150\n",
       "arbejd          132\n",
       "så              114\n",
       "strejk          113\n",
       "vær             109\n",
       "mang            108\n",
       "dansk           104\n",
       "kom              91\n",
       "bliv             82\n",
       "bland            76\n",
       "land             74\n",
       "ell              69\n",
       "år               67\n",
       "patient          66\n",
       "and              66\n",
       "region           66\n",
       "ansat            65\n",
       "få               62\n",
       "mangl            60\n",
       "får              59\n",
       "andr             58\n",
       "uddan            57\n",
       "kun              56\n",
       "procent          52\n",
       "dag              50\n",
       "sygehus          49\n",
       "sygeplejersk     48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_relevant_bow1[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_relevant_bow1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5e6e6369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' fået autorisation norg næst tredobl år kris fyring ansættelsesstop får fået autorisation norg næst tredobl år kris fyring ansættelsesstop får tag norg arbejd sygeplejersk brænd fag helt natur søg derh tredobl år kris fyring ansættelsesstop får sygeplejersk tag norg arbejd brænd fag helt natur søg derh arbejd desvær situation danmark arbejd desvær situation danmark arbejdsgiv valg ikk ansæt all kompetent meg bekymr gret christens formand dansk sygeplejeråd senest tal vis gret christens formand dansk sygeplejeråd senest tal vis antal dansk fået autorisation norg steg januar januar helt afgør herhjem får steg januar januar helt afgør herhjem får gjort mul tilbyd job kommun region gret christens'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_relevant.relevant[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "670a4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix_sum.to_csv(\"dr_word_frequency.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff9ac7",
   "metadata": {},
   "source": [
    "#### TV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "00e3e902",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/1349431805.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstemmed_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtv2_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mstems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstem_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mstemmed_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/3528421427.py\u001b[0m in \u001b[0;36mstem_sentences\u001b[1;34m(document)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnon_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_alpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mstemmed_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# all words in a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mno_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstemmed_tokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_stop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/3528421427.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnon_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_alpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mstemmed_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# all words in a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mno_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstemmed_tokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_stop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\snowball.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;31m# STEP 4: Undouble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdouble_cons\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__double_consonants\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdouble_cons\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m                 \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stemmed_list=[]\n",
    "for i in tv2_2['content']:\n",
    "    stems=stem_sentences(i)\n",
    "    stemmed_list.append(stems)\n",
    "\n",
    "tv2_2['stems']=stemmed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f50b7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer() #Store the class in 'count' to ease coding\n",
    "count_array = tv2_2['stems'] #Take the first two reviews and store them in an array\n",
    "bag = count.fit_transform(count_array) #fit_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "251d7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = bag.toarray() #Make the bag to an array\n",
    "matrix = pd.DataFrame(data=array,columns = count.get_feature_names()) #Input the bag and the words into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "094d143e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_sum = matrix.sum().transpose()\n",
    "matrix_sum.sort_values(ascending = False)\n",
    "matrix_sum.to_csv(\"tv2_word_frequency.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923346e0",
   "metadata": {},
   "source": [
    "#### Folketinget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "917613a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 296/296 [01:50<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "stemmed_list=[]\n",
    "for i in tqdm.tqdm(ft_2['content']):\n",
    "    stems=stem_sentences(i)\n",
    "    stemmed_list.append(stems)\n",
    "\n",
    "ft_2['stems']=stemmed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e25be3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer() #Store the class in 'count' to ease coding\n",
    "count_array = ft_2['stems'] #Take the first two reviews and store them in an array\n",
    "bag = count.fit_transform(count_array) #fit_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f5f14c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = bag.toarray() #Make the bag to an array\n",
    "matrix = pd.DataFrame(data=array,columns = count.get_feature_names()) #Input the bag and the words into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2642c0b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ikk                               98174\n",
       "så                                82428\n",
       "kan                               63835\n",
       "vær                               45419\n",
       "kom                               30076\n",
       "                                  ...  \n",
       "landedokumentationskontor             1\n",
       "landdistriktsvækstpilotordning        1\n",
       "landdistriktsudspil                   1\n",
       "landdistriktssegment                  1\n",
       "øvsag                                 1\n",
       "Length: 45808, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sum = matrix.sum().transpose()\n",
    "matrix_sum.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee7d69",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aba7ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(df):\n",
    "    ############################## bag #################################\n",
    "    count = CountVectorizer() #Choose only 2-grams\n",
    "    \n",
    "    df_array = df['stems']\n",
    "    bag = count.fit_transform(df_array)\n",
    "    ############################## bag #################################\n",
    "    \n",
    "    tfidf = TfidfTransformer()\n",
    "    bag_tfidf = tfidf.fit_transform(bag) \n",
    "\n",
    "    tfidf_array = bag_tfidf.toarray() #Make the bag to an array\n",
    "    matrix_tfidf = pd.DataFrame(data=tfidf_array,columns = count.get_feature_names())\n",
    "    return matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ab651406",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = tfidf(dr_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "56d17cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aabenraa</th>\n",
       "      <th>aag</th>\n",
       "      <th>aagaard</th>\n",
       "      <th>aahaug</th>\n",
       "      <th>aaholm</th>\n",
       "      <th>aalborg</th>\n",
       "      <th>aarhus</th>\n",
       "      <th>aarhusiansk</th>\n",
       "      <th>aaskov</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>østjylland</th>\n",
       "      <th>østjysk</th>\n",
       "      <th>østkyst</th>\n",
       "      <th>østr</th>\n",
       "      <th>øve</th>\n",
       "      <th>øvels</th>\n",
       "      <th>øver</th>\n",
       "      <th>øverst</th>\n",
       "      <th>øvet</th>\n",
       "      <th>øvr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528 rows × 9194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aabenraa  aag  aagaard  aahaug  aaholm   aalborg  aarhus  aarhusiansk  \\\n",
       "0         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "1         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "2         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "3         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "4         0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "..        ...  ...      ...     ...     ...       ...     ...          ...   \n",
       "523       0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "524       0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "525       0.0  0.0      0.0     0.0     0.0  0.034848     0.0          0.0   \n",
       "526       0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "527       0.0  0.0      0.0     0.0     0.0  0.000000     0.0          0.0   \n",
       "\n",
       "     aaskov  abc  ...  østjylland  østjysk  østkyst  østr  øve  øvels  øver  \\\n",
       "0       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "1       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "2       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "3       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "4       0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "..      ...  ...  ...         ...      ...      ...   ...  ...    ...   ...   \n",
       "523     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "524     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "525     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "526     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "527     0.0  0.0  ...         0.0      0.0      0.0   0.0  0.0    0.0   0.0   \n",
       "\n",
       "     øverst  øvet  øvr  \n",
       "0       0.0   0.0  0.0  \n",
       "1       0.0   0.0  0.0  \n",
       "2       0.0   0.0  0.0  \n",
       "3       0.0   0.0  0.0  \n",
       "4       0.0   0.0  0.0  \n",
       "..      ...   ...  ...  \n",
       "523     0.0   0.0  0.0  \n",
       "524     0.0   0.0  0.0  \n",
       "525     0.0   0.0  0.0  \n",
       "526     0.0   0.0  0.0  \n",
       "527     0.0   0.0  0.0  \n",
       "\n",
       "[528 rows x 9194 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f808359",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8ac811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jgb569\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get stopwords list\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('danish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfcf4b",
   "metadata": {},
   "source": [
    "### Tokenized content for three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a709a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords from token-list\n",
    "dr_nostop = [word for word in dr_2_tokens if not word in stopwords]\n",
    "tv2_nostop = [word for word in tv2_2_tokens if not word in stopwords]\n",
    "ft_nostop = [word for word in ft_2_tokens if not word in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6924fbc7",
   "metadata": {},
   "source": [
    "### Create set of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f54baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_complete = dr_nostop + tv2_nostop + ft_nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcae9b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['antallet',\n",
       " 'danske',\n",
       " 'sygeplejersker',\n",
       " 'fået',\n",
       " 'autorisation',\n",
       " 'norge',\n",
       " 'næsten',\n",
       " 'tredoblet',\n",
       " 'år',\n",
       " 'krise',\n",
       " 'fyringer',\n",
       " 'ansættelsesstop',\n",
       " 'får',\n",
       " 'sygeplejerskerne',\n",
       " 'tage',\n",
       " 'norge',\n",
       " 'arbejde',\n",
       " 'sygeplejersker',\n",
       " 'brænder',\n",
       " 'fag',\n",
       " 'helt',\n",
       " 'naturligt',\n",
       " 'søger',\n",
       " 'derhen',\n",
       " 'arbejde',\n",
       " 'desværre',\n",
       " 'situation',\n",
       " 'danmark',\n",
       " 'arbejdsgiverne',\n",
       " 'valgt',\n",
       " 'ansætte',\n",
       " 'kompetente',\n",
       " 'sygeplejersker',\n",
       " 'bekymrende',\n",
       " 'siger',\n",
       " 'grete',\n",
       " 'christensen',\n",
       " 'formand',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'seneste',\n",
       " 'tal',\n",
       " 'viser',\n",
       " 'antallet',\n",
       " 'danske',\n",
       " 'sygeplejersker',\n",
       " 'fået',\n",
       " 'autorisation',\n",
       " 'norge',\n",
       " 'steget',\n",
       " '154',\n",
       " 'januar',\n",
       " '2010',\n",
       " '434',\n",
       " 'januar',\n",
       " '2011',\n",
       " 'helt',\n",
       " 'afgørende',\n",
       " 'herhjemme',\n",
       " 'får',\n",
       " 'gjort',\n",
       " 'muligt',\n",
       " 'tilbyde',\n",
       " 'vores',\n",
       " 'sygeplejersker',\n",
       " 'job',\n",
       " 'kommuner',\n",
       " 'regionerne',\n",
       " 'siger',\n",
       " 'grete',\n",
       " 'christensen',\n",
       " 'trods',\n",
       " 'fyringsrunder',\n",
       " 'sygehusene',\n",
       " 'både',\n",
       " '2010',\n",
       " '2011',\n",
       " 'nedlæggelse',\n",
       " 'sygehuse',\n",
       " 'faxe',\n",
       " 'nakskov',\n",
       " 'kalundborg',\n",
       " 'så',\n",
       " 'få',\n",
       " 'arbejdsløse',\n",
       " 'sygeplejersker',\n",
       " 'region',\n",
       " 'sjælland',\n",
       " 'seneste',\n",
       " 'tal',\n",
       " 'viser',\n",
       " '85',\n",
       " 'ledige',\n",
       " 'arbejdsløsheds',\n",
       " 'procent',\n",
       " 'ca',\n",
       " 'kredsformand',\n",
       " 'helle',\n",
       " 'dirksen',\n",
       " 'tvivl',\n",
       " 'ledige',\n",
       " 'simpelthen',\n",
       " 'rejst',\n",
       " 'andre',\n",
       " 'steder',\n",
       " 'hen',\n",
       " 'mener',\n",
       " 'sygeplejerskerne',\n",
       " 'protesterede',\n",
       " 'voldsomt',\n",
       " 'fyringsrunderne',\n",
       " 'kan',\n",
       " 'godt',\n",
       " 'se',\n",
       " 'andre',\n",
       " 'faggrupper',\n",
       " 'hårdere',\n",
       " 'ramt',\n",
       " 'vores',\n",
       " 'bekymring',\n",
       " 'gik',\n",
       " 'især',\n",
       " 'nyuddannede',\n",
       " 'svært',\n",
       " 'ved',\n",
       " 'finmde',\n",
       " 'fodfæste',\n",
       " 'arbejdsmarkedet',\n",
       " 'siger',\n",
       " 'helle',\n",
       " 'dirksen',\n",
       " 'knap',\n",
       " 'halvdelen',\n",
       " '85',\n",
       " 'ledige',\n",
       " 'november',\n",
       " 'nyuddannede',\n",
       " 'februar',\n",
       " 'nyt',\n",
       " 'hold',\n",
       " 'sygeplejersker',\n",
       " 'færdige',\n",
       " 'sygeplejeskolerne',\n",
       " 'undskylde',\n",
       " 'beklage',\n",
       " 'formanden',\n",
       " 'region',\n",
       " 'sjælland',\n",
       " 'steen',\n",
       " 'bach',\n",
       " 'nielsen',\n",
       " 'tænkt',\n",
       " 'opfylde',\n",
       " 'kravet',\n",
       " 'offentlig',\n",
       " 'undskyldning',\n",
       " 'ansatte',\n",
       " 'sygehuset',\n",
       " 'nykøbing',\n",
       " 'falster',\n",
       " 'dermed',\n",
       " 'spidser',\n",
       " 'striden',\n",
       " 'mellem',\n",
       " 'socialdemokratiske',\n",
       " 'regionsformand',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'rådet',\n",
       " 'truer',\n",
       " 'anmelde',\n",
       " 'steen',\n",
       " 'bach',\n",
       " 'nielsen',\n",
       " 'ombudsmanden',\n",
       " 'krænkelse',\n",
       " 'offentligt',\n",
       " 'ansattes',\n",
       " 'ytringsfrihed',\n",
       " 'fordi',\n",
       " 'sagen',\n",
       " 'overdødelighed',\n",
       " 'sygehuset',\n",
       " 'nykøbing',\n",
       " 'falster',\n",
       " 'stærkt',\n",
       " 'opfordrede',\n",
       " 'lokalt',\n",
       " 'ansatte',\n",
       " 'sygeplejersker',\n",
       " 'samarbejde',\n",
       " 'stedet',\n",
       " 'diskutere',\n",
       " 'via',\n",
       " 'peressen',\n",
       " 'regionsformanden',\n",
       " 'kan',\n",
       " 'forstå',\n",
       " 'sygeplejerskerne',\n",
       " 'opfattet',\n",
       " 'lade',\n",
       " 'ytre',\n",
       " 'kritik',\n",
       " 'offentlige',\n",
       " 'kan',\n",
       " 'sige',\n",
       " 'undskyld',\n",
       " 'fordi',\n",
       " 'gerne',\n",
       " 'dialog',\n",
       " 'mener',\n",
       " 'steen',\n",
       " 'bach',\n",
       " 'nielsen',\n",
       " 'aftalt',\n",
       " 'møde',\n",
       " 'onsdag',\n",
       " 'formiddagmellem',\n",
       " 'region',\n",
       " 'sjælland',\n",
       " 'ogdansk',\n",
       " 'sygeplejeråd',\n",
       " 'kredsformand',\n",
       " 'helle',\n",
       " 'dirksen',\n",
       " 'siger',\n",
       " 'inden',\n",
       " 'mødet',\n",
       " 'dsr',\n",
       " 'står',\n",
       " 'fast',\n",
       " 'kravet',\n",
       " 'offentlig',\n",
       " 'undskyldning',\n",
       " 'beklagelse',\n",
       " 'overfor',\n",
       " 'fællestillidsmanden',\n",
       " 'sygeplejerskerne',\n",
       " 'nykøbing',\n",
       " 'falster',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'repræsenterer',\n",
       " 'landets',\n",
       " 'omkring',\n",
       " '70',\n",
       " '000',\n",
       " 'sygeplejersker',\n",
       " 'mener',\n",
       " 'muligt',\n",
       " 'medarbejdere',\n",
       " 'kun',\n",
       " 'tage',\n",
       " 'højst',\n",
       " 'to',\n",
       " 'nattevagter',\n",
       " 'træk',\n",
       " 'meldingen',\n",
       " 'kommer',\n",
       " 'baggrund',\n",
       " 'anbefalinger',\n",
       " 'danske',\n",
       " 'internationale',\n",
       " 'eksperter',\n",
       " 'hvordan',\n",
       " 'forebygger',\n",
       " 'brystkræft',\n",
       " 'ved',\n",
       " 'natarbejde',\n",
       " 'blandt',\n",
       " 'rådene',\n",
       " 'hurtigt',\n",
       " 'roterende',\n",
       " 'vagtskift',\n",
       " 'kun',\n",
       " 'to',\n",
       " 'hinanden',\n",
       " 'følgende',\n",
       " 'nattevagter',\n",
       " 'fremfor',\n",
       " 'tre',\n",
       " 'flere',\n",
       " 'nattevagter',\n",
       " 'træk',\n",
       " 'rigtig',\n",
       " 'godt',\n",
       " 'eksperterne',\n",
       " 'kommer',\n",
       " 'konkrete',\n",
       " 'anbefalinger',\n",
       " 'højst',\n",
       " 'to',\n",
       " 'nattevagter',\n",
       " 'træk',\n",
       " 'øjne',\n",
       " 'klareste',\n",
       " 'anbefaling',\n",
       " 'siger',\n",
       " 'dorte',\n",
       " 'steenberg',\n",
       " 'næstformand',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'fortsætter',\n",
       " 'går',\n",
       " 'arbejdsgiverne',\n",
       " 'tage',\n",
       " 'ansvar',\n",
       " 'sørge',\n",
       " 'muligt',\n",
       " 'medarbejderne',\n",
       " 'følge',\n",
       " 'eksperternes',\n",
       " 'råd',\n",
       " 'helt',\n",
       " 'nødvendigt',\n",
       " 'sygeplejersker',\n",
       " 'arbejder',\n",
       " 'natten',\n",
       " 'tager',\n",
       " 'patienter',\n",
       " 'undersøgelser',\n",
       " 'vist',\n",
       " 'klar',\n",
       " 'sammenhæng',\n",
       " 'mellem',\n",
       " 'brystkræft',\n",
       " 'natarbejde',\n",
       " 'så',\n",
       " 'forpligtelse',\n",
       " 'gøre',\n",
       " 'kan',\n",
       " 'forebygge',\n",
       " 'medarbejdere',\n",
       " 'syge',\n",
       " 'siger',\n",
       " 'ekspertanbefaling',\n",
       " 'tilrettelægge',\n",
       " 'arbejdet',\n",
       " 'uret',\n",
       " 'så',\n",
       " 'ens',\n",
       " 'vagter',\n",
       " 'går',\n",
       " 'dag',\n",
       " 'aften',\n",
       " 'aften',\n",
       " 'nat',\n",
       " 'nat',\n",
       " 'dag',\n",
       " 'ifølge',\n",
       " 'undersøgelser',\n",
       " 'giver',\n",
       " 'mindre',\n",
       " 'forstyrrelse',\n",
       " 'døgnrytmen',\n",
       " 'døgnrytmen',\n",
       " 'hele',\n",
       " 'tiden',\n",
       " 'udfordret',\n",
       " 'så',\n",
       " 'stresser',\n",
       " 'kroppen',\n",
       " 'kan',\n",
       " 'negativ',\n",
       " 'effekt',\n",
       " 'derfor',\n",
       " 'helt',\n",
       " 'afgørende',\n",
       " 'sørger',\n",
       " 'lave',\n",
       " 'vagtplaner',\n",
       " 'følger',\n",
       " 'uret',\n",
       " 'så',\n",
       " 'mindst',\n",
       " 'muligt',\n",
       " 'pres',\n",
       " 'forløbene',\n",
       " 'mere',\n",
       " 'naturlige',\n",
       " 'siger',\n",
       " 'dorte',\n",
       " 'steenberg',\n",
       " 'ritzau',\n",
       " 'slut',\n",
       " 'sygeplejerudtryk',\n",
       " 'gebrokkent',\n",
       " 'dansk',\n",
       " 'nordjyske',\n",
       " 'sygehuse',\n",
       " 'få',\n",
       " 'år',\n",
       " 'siden',\n",
       " 'måtte',\n",
       " 'sygehusene',\n",
       " 'importere',\n",
       " 'sygeplejersker',\n",
       " 'tyskland',\n",
       " 'siden',\n",
       " 'besparelser',\n",
       " 'betydet',\n",
       " 'ledige',\n",
       " 'danske',\n",
       " 'sygeplejersker',\n",
       " 'så',\n",
       " 'længere',\n",
       " 'bruge',\n",
       " 'hente',\n",
       " 'sygeplejersker',\n",
       " 'andre',\n",
       " 'lande',\n",
       " 'øjeblikket',\n",
       " 'ingen',\n",
       " 'interesse',\n",
       " 'rekruttere',\n",
       " 'udenlandske',\n",
       " 'sygeplejersker',\n",
       " 'fortæller',\n",
       " 'jytte',\n",
       " 'wester',\n",
       " 'formand',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'nordjylland',\n",
       " 'tilbage',\n",
       " '2008',\n",
       " 'håndtere',\n",
       " 'region',\n",
       " 'nordjylland',\n",
       " 'lavede',\n",
       " 'aftale',\n",
       " 'mere',\n",
       " '40',\n",
       " 'tyske',\n",
       " 'sygeplejersker',\n",
       " 'fordi',\n",
       " 'manglede',\n",
       " 'arbejdskraft',\n",
       " 'dag',\n",
       " 'må',\n",
       " 'jytte',\n",
       " 'wester',\n",
       " 'stedet',\n",
       " 'guide',\n",
       " 'medlemmer',\n",
       " 'kan',\n",
       " 'få',\n",
       " 'arbejde',\n",
       " 'øjeblikket',\n",
       " 'værste',\n",
       " 'situation',\n",
       " 'haft',\n",
       " 'år',\n",
       " 'arbejdsløse',\n",
       " 'sygeplejersker',\n",
       " 'kø',\n",
       " 'vokser',\n",
       " 'vokser',\n",
       " 'siger',\n",
       " 'gang',\n",
       " 'brugte',\n",
       " 'regionen',\n",
       " 'penge',\n",
       " 'lære',\n",
       " 'udenlandske',\n",
       " 'sygeplejersker',\n",
       " 'dansk',\n",
       " 'integrere',\n",
       " 'nødvendighed',\n",
       " 'mener',\n",
       " 'jytte',\n",
       " 'wester',\n",
       " 'hjælp',\n",
       " 'få',\n",
       " 'tilstrækkelig',\n",
       " 'arbejdskraft',\n",
       " 'gjorde',\n",
       " 'indsats',\n",
       " 'få',\n",
       " 'tilstrækkeligt',\n",
       " 'sygeplejersker',\n",
       " 'siger',\n",
       " 'sygeplejersker',\n",
       " 'stor',\n",
       " 'stil',\n",
       " 'uddannet',\n",
       " 'ledighed',\n",
       " '85',\n",
       " 'procent',\n",
       " 'nyuddannede',\n",
       " 'sygeplejersker',\n",
       " 'uddannelserne',\n",
       " 'viborg',\n",
       " 'holstebro',\n",
       " 'arbejdsløse',\n",
       " 'så',\n",
       " 'går',\n",
       " 'tre',\n",
       " 'halvt',\n",
       " 'år',\n",
       " 'su',\n",
       " 'ogstudie',\n",
       " 'så',\n",
       " 'kommer',\n",
       " 'arbejdsmarked',\n",
       " 'arbejde',\n",
       " 'få',\n",
       " 'siger',\n",
       " 'anita',\n",
       " 'staarup',\n",
       " 'nyuddannede',\n",
       " 'sygeplejersker',\n",
       " 'nyuddannede',\n",
       " 'holstebro',\n",
       " 'kommer',\n",
       " 'arbejdsløshed',\n",
       " 'mens',\n",
       " 'kun',\n",
       " 'syv',\n",
       " 'sygeplejersker',\n",
       " 'uddannelsen',\n",
       " 'viborg',\n",
       " 'job',\n",
       " 'seneste',\n",
       " 'halve',\n",
       " 'års',\n",
       " 'tid',\n",
       " '200',\n",
       " 'sygeplejersker',\n",
       " 'blevet',\n",
       " 'fyret',\n",
       " 'ved',\n",
       " 'hospitalsenheden',\n",
       " 'vest',\n",
       " 'sygehuset',\n",
       " 'viborg',\n",
       " 'giver',\n",
       " 'endnu',\n",
       " 'ringere',\n",
       " 'chancer',\n",
       " 'lyder',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'grund',\n",
       " 'store',\n",
       " 'besparelser',\n",
       " 'igennem',\n",
       " 'region',\n",
       " 'midtjylland',\n",
       " 'så',\n",
       " 'kommet',\n",
       " 'del',\n",
       " 'ledige',\n",
       " 'sygeplejersker',\n",
       " 'samtidig',\n",
       " 'nyuddannede',\n",
       " 'svært',\n",
       " 'ved',\n",
       " 'få',\n",
       " 'job',\n",
       " 'siger',\n",
       " 'bente',\n",
       " 'rasmussen',\n",
       " 'næstformand',\n",
       " 'sygeplejerskerne',\n",
       " 'region',\n",
       " 'midtjylland',\n",
       " 'betyder',\n",
       " 'sygeplejersker',\n",
       " 'søger',\n",
       " 'udlandet',\n",
       " 'eksempel',\n",
       " 'norge',\n",
       " 'arbejde',\n",
       " 'få',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'region',\n",
       " 'midtjylland',\n",
       " 'holder',\n",
       " 'jobmesse',\n",
       " '6',\n",
       " 'marts',\n",
       " 'mulighed',\n",
       " 'høre',\n",
       " 'ledige',\n",
       " 'stillinger',\n",
       " 'norge',\n",
       " 'viborg',\n",
       " 'kommune',\n",
       " 'kører',\n",
       " 'projekt',\n",
       " 'jobrotation',\n",
       " 'sygeplejersker',\n",
       " 'arbejder',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'starte',\n",
       " 'holstebro',\n",
       " 'området',\n",
       " 'lige',\n",
       " '237',\n",
       " 'ledige',\n",
       " 'sygeplejersker',\n",
       " 'region',\n",
       " 'midtjylland',\n",
       " 'nyuddannede',\n",
       " 'sygeplejersker',\n",
       " 'svært',\n",
       " 'ved',\n",
       " 'finde',\n",
       " 'arbejde',\n",
       " '17',\n",
       " 'procent',\n",
       " 'nyuddannede',\n",
       " 'sidste',\n",
       " 'sommers',\n",
       " 'hold',\n",
       " 'trillet',\n",
       " 'tommelfingre',\n",
       " 'lang',\n",
       " 'tid',\n",
       " 'syddanmark',\n",
       " 'billedet',\n",
       " 'lidt',\n",
       " 'mere',\n",
       " 'positivt',\n",
       " 'glæder',\n",
       " 'formanden',\n",
       " 'dansk',\n",
       " 'sygeplejeråd',\n",
       " 'syddanmark',\n",
       " 'john',\n",
       " 'christiansen',\n",
       " 'primære',\n",
       " 'forklaring',\n",
       " 'især',\n",
       " 'sygehusområdet',\n",
       " 'indset',\n",
       " 'vigtigt',\n",
       " 'lidt',\n",
       " 'højere',\n",
       " 'normering',\n",
       " 'bruge',\n",
       " 'eksterne',\n",
       " 'vikarer',\n",
       " 'så',\n",
       " 'betyder',\n",
       " 'fastansat',\n",
       " 'lidt',\n",
       " 'flere',\n",
       " 'sygeplejerske',\n",
       " 'sygehusområdet',\n",
       " 'tidligere',\n",
       " 'siger',\n",
       " 'hurtigere',\n",
       " 'adgang',\n",
       " 'arbejdsmarkedet',\n",
       " 'ifølge',\n",
       " 'sygeplejerskenes',\n",
       " 'formand',\n",
       " 'vigtigt',\n",
       " 'få',\n",
       " 'god',\n",
       " 'start',\n",
       " 'faget',\n",
       " 'gør',\n",
       " 'rodfæstes',\n",
       " 'hurtigere',\n",
       " 'enkelte',\n",
       " 'sygeplejerske',\n",
       " 'betyder',\n",
       " 'bedre',\n",
       " 'kan',\n",
       " 'etablere',\n",
       " 'private',\n",
       " 'liv',\n",
       " 'betyder',\n",
       " 'sandsynligheden',\n",
       " 'indenfor',\n",
       " 'sygeplejerskefaget',\n",
       " 'større',\n",
       " 'siger',\n",
       " 'john',\n",
       " 'christiansen',\n",
       " 'blevet',\n",
       " 'sværere',\n",
       " 'nyuddannede',\n",
       " 'sygeplejersker',\n",
       " 'finde',\n",
       " 'job',\n",
       " 'ledigheden',\n",
       " 'landsplan',\n",
       " 'steget',\n",
       " '2',\n",
       " '17',\n",
       " 'procent',\n",
       " 'menhvis',\n",
       " 'heldet',\n",
       " 'overveje',\n",
       " 'flytte',\n",
       " 'region',\n",
       " 'syddanmark',\n",
       " 'nemlig',\n",
       " 'størst',\n",
       " 'chance',\n",
       " 'ansat',\n",
       " 'formand',\n",
       " 'sygeplejerådet',\n",
       " 'syddanmark',\n",
       " 'john',\n",
       " 'christiansen',\n",
       " 'tror',\n",
       " 'skyldes',\n",
       " 'ændret',\n",
       " 'forhold',\n",
       " 'mellem',\n",
       " 'vikarer',\n",
       " 'fastansatte',\n",
       " 'især',\n",
       " 'sygehusområdet',\n",
       " 'indset',\n",
       " 'deter',\n",
       " 'vigtigt',\n",
       " 'lidt',\n",
       " 'højere',\n",
       " 'nomering',\n",
       " 'bruge',\n",
       " 'eksterne',\n",
       " 'vikarer',\n",
       " 'betyder',\n",
       " 'manhar',\n",
       " 'ansat',\n",
       " 'lidt',\n",
       " 'flere',\n",
       " 'sygeplejerskerpå',\n",
       " 'sygehusområdet',\n",
       " 'tidligere',\n",
       " 'hanmener',\n",
       " 'hurtige',\n",
       " 'adgang',\n",
       " 'arbejdsmarkedet',\n",
       " 'vigtig',\n",
       " 'sygeplejerskerne',\n",
       " 'kommer',\n",
       " 'godt',\n",
       " 'faget',\n",
       " 'rodfæstes',\n",
       " 'langt',\n",
       " 'hurtigere',\n",
       " 'helt',\n",
       " 'personligt',\n",
       " 'enkelte',\n",
       " 'sygeplejerske',\n",
       " 'gør',\n",
       " 'selvfølgelig',\n",
       " 'bedre',\n",
       " 'kan',\n",
       " 'etablere',\n",
       " 'private',\n",
       " 'liv',\n",
       " 'kan',\n",
       " 'huskøb',\n",
       " 'ellerdet',\n",
       " 'få',\n",
       " 'børn',\n",
       " 'betyder',\n",
       " 'sandsynligheden',\n",
       " 'så',\n",
       " 'inden',\n",
       " 'sygeplejerskefaget',\n",
       " 'større',\n",
       " 'siger',\n",
       " 'john',\n",
       " 'christiansen',\n",
       " 'http',\n",
       " 'mu',\n",
       " 'net',\n",
       " 'dr',\n",
       " 'dk',\n",
       " 'admin',\n",
       " 'programcard',\n",
       " 'get',\n",
       " 'id',\n",
       " 'urn',\n",
       " 'dr',\n",
       " 'mu',\n",
       " 'programcard',\n",
       " '54f47a6f6187a411cc6fcdb0http',\n",
       " 'mu',\n",
       " 'net',\n",
       " 'dr',\n",
       " 'dk',\n",
       " 'admin',\n",
       " 'programcard',\n",
       " 'get',\n",
       " 'id',\n",
       " 'urn',\n",
       " 'dr',\n",
       " 'mu',\n",
       " 'programcard',\n",
       " '550949d96187a912fce98132',\n",
       " 'nye',\n",
       " 'akutlinje',\n",
       " 'region',\n",
       " 'hovedstaden',\n",
       " 'specialuddannede',\n",
       " 'sygeplejersker',\n",
       " 'står',\n",
       " 'klar',\n",
       " 'rådgive',\n",
       " 'får',\n",
       " 'hug',\n",
       " 'lægeforeningen',\n",
       " 'skriver',\n",
       " 'ugeskrift',\n",
       " 'læger',\n",
       " 'region',\n",
       " 'hovedstaden',\n",
       " 'råder',\n",
       " 'stort',\n",
       " 'antal',\n",
       " 'vagtlæger',\n",
       " 'eksperter',\n",
       " 'burde',\n",
       " 'overlade',\n",
       " 'rent',\n",
       " 'faktisk',\n",
       " 'kan',\n",
       " 'lave',\n",
       " 'slags',\n",
       " 'opgaver',\n",
       " 'udføre',\n",
       " 'siger',\n",
       " 'lægeforeningens',\n",
       " 'formand',\n",
       " 'mads',\n",
       " 'koch',\n",
       " 'hansen',\n",
       " 'ugeskrift',\n",
       " 'læger',\n",
       " 'kan',\n",
       " 'både',\n",
       " 'stille',\n",
       " 'diagnose',\n",
       " 'fortælle',\n",
       " 'præcist',\n",
       " 'patienten',\n",
       " 'gå',\n",
       " 'hen',\n",
       " 'videre',\n",
       " 'systemet',\n",
       " 'hvorfor',\n",
       " 'starte',\n",
       " 'lægen',\n",
       " 'gør',\n",
       " 'andre',\n",
       " 'steder',\n",
       " 'synes',\n",
       " 'tilbud',\n",
       " 'overflødigt',\n",
       " 'må',\n",
       " 'forvirre',\n",
       " 'patienten',\n",
       " 'siger',\n",
       " 'akuttelefonen',\n",
       " '1813',\n",
       " 'startede',\n",
       " '30',\n",
       " 'januar',\n",
       " 'specialuddannet',\n",
       " 'sygeplejerske',\n",
       " 'modtager',\n",
       " 'opkald',\n",
       " 'døgnet',\n",
       " 'rundt',\n",
       " 'henviser',\n",
       " 'yderligere',\n",
       " 'behandling',\n",
       " 'vurderer',\n",
       " 'nødvendigt',\n",
       " 'snit',\n",
       " '600',\n",
       " 'opkald',\n",
       " 'døgnet',\n",
       " 'direktør',\n",
       " 'akutberedskabet',\n",
       " 'region',\n",
       " 'hovedstaden',\n",
       " 'freddy',\n",
       " 'lippert',\n",
       " 'forstår',\n",
       " 'kritikken',\n",
       " 'ønsker',\n",
       " 'dels',\n",
       " 'aflaste',\n",
       " 'vores',\n",
       " 'akutmodtagelser',\n",
       " 'dels',\n",
       " 'hjælpe',\n",
       " 'borgerne',\n",
       " 'let',\n",
       " 'adgang',\n",
       " 'relevante',\n",
       " 'behandling',\n",
       " 'derfor',\n",
       " 'samlet',\n",
       " 'tilbud',\n",
       " 'sted',\n",
       " 'fagfolk',\n",
       " 'sidder',\n",
       " 'klar',\n",
       " '24',\n",
       " 'timer',\n",
       " 'døgnet',\n",
       " 'forklarer',\n",
       " 'borgeren',\n",
       " 'søge',\n",
       " 'hjælp',\n",
       " '112',\n",
       " 'akutte',\n",
       " 'livstruende',\n",
       " 'hændelser',\n",
       " '1813',\n",
       " 'døgntilbud',\n",
       " 'borgerne',\n",
       " 'siger',\n",
       " 'samtidig',\n",
       " 'kritiserer',\n",
       " 'forbrugerrådet',\n",
       " 'måde',\n",
       " 'regionen',\n",
       " 'reklameret',\n",
       " 'akutlinjen',\n",
       " 'grænsen',\n",
       " 'lovlige',\n",
       " 'sundhedsstyrelsen',\n",
       " 'sætter',\n",
       " 'forbrugerrådet',\n",
       " 'plads',\n",
       " 'sagen',\n",
       " 'nye',\n",
       " 'akutlinje',\n",
       " '1813',\n",
       " 'region',\n",
       " 'hovedstaden',\n",
       " 'sidder',\n",
       " 'specialudannede',\n",
       " 'sygeplejersker',\n",
       " 'klar',\n",
       " 'ved',\n",
       " 'telefonen',\n",
       " 'rådgive',\n",
       " 'borgere',\n",
       " 'søger',\n",
       " 'sundhedsfaglige',\n",
       " 'råd',\n",
       " 'vejledning',\n",
       " 'lægeforeningen',\n",
       " 'ude',\n",
       " 'akutlinjen',\n",
       " 'mener',\n",
       " 'forvirrer',\n",
       " 'patienterne',\n",
       " 'desuden',\n",
       " 'forbrugerrådet',\n",
       " 'kritiseret',\n",
       " 'region',\n",
       " 'hovedstadens',\n",
       " 'reklamer',\n",
       " 'mener',\n",
       " 'kant',\n",
       " 'loven',\n",
       " 'henvist',\n",
       " 'forbudt',\n",
       " 'andre',\n",
       " 'læger',\n",
       " 'stille',\n",
       " 'diagnoser',\n",
       " 'påstand',\n",
       " 'maner',\n",
       " 'sundhedsstyrelsen',\n",
       " 'jorden',\n",
       " 'forbeholdt',\n",
       " 'nogen',\n",
       " 'helst',\n",
       " 'stille',\n",
       " 'diagnoser',\n",
       " 'siger',\n",
       " 'anne',\n",
       " 'mette',\n",
       " 'dons',\n",
       " 'chef',\n",
       " 'tilsyn',\n",
       " 'patientsikkerhed',\n",
       " 'sundhedsstyrelsen',\n",
       " 'dsr',\n",
       " 'dk',\n",
       " 'står',\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938e7a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5356096"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb93db8",
   "metadata": {},
   "source": [
    "The total number of words across our three datasets is 5356096."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435339b",
   "metadata": {},
   "source": [
    "Our unique wordset contains 115189 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b37dd",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04392ec",
   "metadata": {},
   "source": [
    "### Stemming of content by source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "146aa8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sourcestemmer(wordlist):\n",
    "    wordlist_stemmed = [stemmer.stem(word) for word in wordlist]\n",
    "    return wordlist_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34860fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_stemmed = sourcestemmer(dr_nostop)\n",
    "tv2_stemmed = sourcestemmer(tv2_nostop)\n",
    "ft_stemmed = sourcestemmer(ft_nostop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27620ad3",
   "metadata": {},
   "source": [
    "### Wordcount for complete content of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88c2d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting lists together to one large string as preprocessing for wordcount\n",
    "dr_string = \" \".join(dr_stemmed)\n",
    "tv2_string = \" \".join(tv2_stemmed)\n",
    "ft_string = \" \".join(ft_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ab8e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c557c",
   "metadata": {},
   "source": [
    "#### DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85890600",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.96 GiB for an array with shape (125596, 9574) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/2318576253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Make the bag to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Input the bag and the words into a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmatrix_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmatrix_sum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.96 GiB for an array with shape (125596, 9574) and data type int64"
     ]
    }
   ],
   "source": [
    "#Store the class in 'count' to ease coding\n",
    "dr_bag = count.fit_transform(dr_stemmed) #fit_transform takes an array as input and outputs the bag of words\n",
    "\n",
    "dr_count_array = dr_bag.toarray() #Make the bag to an array\n",
    "dr_matrix = pd.DataFrame(data=dr_count_array,columns = count.get_feature_names_out()) #Input the bag and the words into a dataframe\n",
    "dr_matrix_sum = dr_matrix.sum().transpose()\n",
    "dr_matrix_sum.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f7fc8ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'list_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17052/2305459028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'os' has no attribute 'list_dir'"
     ]
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5419c6",
   "metadata": {},
   "source": [
    "#### TV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83685314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the class in 'count' to ease coding\n",
    "tv2_bag = count.fit_transform(tv2_stemmed) #fit_transform takes an array as input and outputs the bag of words\n",
    "\n",
    "tv2_array = tv2_bag.toarray() #Make the bag to an array\n",
    "tv2_matrix = pd.DataFrame(data=tv2_array,columns = count.get_feature_names_out()) #Input the bag and the words into a dataframe\n",
    "tv2_matrix_sum = tv2_matrix.sum().transpose()\n",
    "tv2_matrix_sum.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596429a",
   "metadata": {},
   "source": [
    "#### Folketinget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the class in 'count' to ease coding\n",
    "ft_bag = count.fit_transform(ft_stemmed) #fit_transform takes an array as input and outputs the bag of words\n",
    "\n",
    "ft_count_array = ft_bag.toarray() #Make the bag to an array\n",
    "ft_matrix = pd.DataFrame(data=ft_count_array,columns = count.get_feature_names_out()) #Input the bag and the words into a dataframe\n",
    "ft_matrix_sum = ft_matrix.sum().transpose()\n",
    "ft_matrix_sum.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203416c2",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ca923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Danish lemmatizer\n",
    "lem = lemmy.load(\"da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_lem = [lem.lemmatize(\"\", word) for word in wordset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list instead of list of list\n",
    "wordlist_lem = [word for sublist in wordlist_lem for word in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06246f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_lem_2 = wordlist_lem_2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73162f63",
   "metadata": {},
   "source": [
    "Comment: The lemmatization returns a list of lists that also contains more than two words which could lead to problems.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374b384",
   "metadata": {},
   "source": [
    "## Stemming and bag of words for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd8447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46df18ca",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
