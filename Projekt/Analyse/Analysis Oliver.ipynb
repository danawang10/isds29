{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdea52a",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9c7cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import lemmy # For lemmatization\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab93cee9",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46bea995",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_sygeplej2x = pd.read_csv('ft_sygeplej2x.csv')\n",
    "dr_sygeplej2x = pd.read_csv('dr_sygeplej2x.csv')\n",
    "tv2_sygeplej2x = pd.read_csv('tv2_sygeplej2x.csv')\n",
    "\n",
    "ft_2 = ft_sygeplej2x.copy() \n",
    "dr_2 = dr_sygeplej2x.copy() \n",
    "tv2_2 = tv2_sygeplej2x.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5272c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06caf73e",
   "metadata": {},
   "source": [
    "## Remove non-alphanumerical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1433dbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g1/m2905s6d6093hshyj_v9xm380000gn/T/ipykernel_23493/1145022020.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['content'] = df['content'].str.replace(r'\\W', ' ')\\\n"
     ]
    }
   ],
   "source": [
    "for df in [ft_2, dr_2, tv2_2]:\n",
    "    df['content'] = df['content'].str.replace(r'\\W', ' ')\\\n",
    "                                 .str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfb5d0",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2adb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/oliver/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download tokenizer\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e201aba-3273-42f0-9fb2-9f1bedda3bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_2['tokenized'] = df.apply(lambda row: nltk.tokenize.word_tokenize(row['content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fbd01b-d6cf-4603-a88f-4f5cec95c055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2b7cdaa-292c-43d9-a872-34b7356dbe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [mens, nyuddannede, danske, sygeplejersker, ha...\n",
       "1      [antallet, af, danske, sygeplejersker, der, ha...\n",
       "2      [en, bevæbnet, mand, har, skudt, og, dræbt, sy...\n",
       "3      [hvert, år, dør, hundredvis, af, patienter, fo...\n",
       "4      [sygeplejersker, lærere, politifolk, og, unge,...\n",
       "                             ...                        \n",
       "523    [sundhedsstyrelsen, kom, torsdag, med, hård, k...\n",
       "524    [stop, det, offentlige, forbrug, og, sænk, ska...\n",
       "525    [der, er, mange, forsinkelser, og, fejl, i, va...\n",
       "526    [36, årige, kirsten, brosbøl, bliver, ny, milj...\n",
       "527    [sundhedsmyndighederne, i, usa, har, mandag, a...\n",
       "Name: tokenized, Length: 528, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " stemmed_tok = [porter_stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e6f6d19-0964-485a-82dd-8937948bc531",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dr_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstemmed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:8839\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8828\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8830\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   8831\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8832\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8837\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   8838\u001b[0m )\n\u001b[0;32m-> 8839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:851\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:867\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    869\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    870\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    871\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dr_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstemmed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: [stemmer\u001b[38;5;241m.\u001b[39mstem([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized\u001b[39m\u001b[38;5;124m'\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dr_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstemmed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: [\u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized\u001b[39m\u001b[38;5;124m'\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/stem/snowball.py:1014\u001b[0m, in \u001b[0;36mDanishStemmer.stem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;124;03mStem a Danish word and return the stemmed form.\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;66;03m# Every word is put into lower case for normalization.\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m word \u001b[38;5;241m=\u001b[39m \u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopwords:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "dr_2['stemmed'] = df.apply(lambda row: [stemmer.stem(['tokenized']) for word in ['tokenized']], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddb67988-aeda-4c4d-8c8f-c5421b65057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens=[stemmer.stem(word) for word in tokens]\n",
    "    no\n",
    "    stems=' '.join(stemmed_tokens)\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc1c2ce2-7ba3-490e-afc3-5998cf5ba8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_list=[]\n",
    "for i in dr_2['content']:\n",
    "    stems=stem_sentences(i)\n",
    "    stemmed_list.append(stems)\n",
    "\n",
    "dr_2['stems']=stemmed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86f8ab6b-6fae-4c3e-b2ad-e175f6789c58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>titles</th>\n",
       "      <th>sub_header</th>\n",
       "      <th>h2</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>tag</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>danske sygeplejersker får job i norge</td>\n",
       "      <td>krise, fyringer og ansættelsesstop får sygeple...</td>\n",
       "      <td>markant flere</td>\n",
       "      <td>antallet af danske sygeplejersker, der har fåe...</td>\n",
       "      <td>ritzau/</td>\n",
       "      <td>Penge</td>\n",
       "      <td>2012-01-19 13:27:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/penge/danske-sygeple...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[mens, nyuddannede, danske, sygeplejersker, ha...</td>\n",
       "      <td>antal af dansk sygeplejersker, der har fået au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>næsten ingen ledige sygeplejersker</td>\n",
       "      <td>trods fyringsrunder i både 2010 og 2011 er arb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trods fyringsrunder på sygehusene i både 2010 ...</td>\n",
       "      <td>henny mortensen</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>2012-01-28 07:42:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/sjaelland/...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[antallet, af, danske, sygeplejersker, der, ha...</td>\n",
       "      <td>trod fyringsrund på sygehus i båd 2010 og 2011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>regionsformand: jeg har ikke noget at undskylde</td>\n",
       "      <td>steen bach nielsen forstår ikke, at sygeplejer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>der er ikke noget at undskylde eller beklage.....</td>\n",
       "      <td>jørgen hansen</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>2012-01-24 15:39:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/sjaelland/...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[en, bevæbnet, mand, har, skudt, og, dræbt, sy...</td>\n",
       "      <td>der er ikk nog at undskyld ell beklage... form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>sygeplejersker vil skære i nattevagter</td>\n",
       "      <td>risiko for at natarbejde er kræftfremkaldende ...</td>\n",
       "      <td>færre nattevagter fast døgnrytme er vigtig</td>\n",
       "      <td>dansk sygeplejeråd, der repræsenterer landets ...</td>\n",
       "      <td>ritzau</td>\n",
       "      <td>Indland</td>\n",
       "      <td>2012-02-21 10:48:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/indland/sygeplejersk...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[hvert, år, dør, hundredvis, af, patienter, fo...</td>\n",
       "      <td>dansk sygeplejeråd, der repræsent land omkring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>udenlandske sygeplejersker er taget hjem</td>\n",
       "      <td>det er slut med sygeplejerudtryk på gebrokkent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>det er slut med sygeplejerudtryk på gebrokkent...</td>\n",
       "      <td>mikkel from nielsen</td>\n",
       "      <td>Nordjylland</td>\n",
       "      <td>2012-02-27 15:26:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/nordjyllan...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[sygeplejersker, lærere, politifolk, og, unge,...</td>\n",
       "      <td>det er slut med sygeplejerudtryk på gebrokkent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>1495</td>\n",
       "      <td>læger og sygeplejersker siger stop: 'kan ikke ...</td>\n",
       "      <td>ifølge ansatte på holbæk sygehus, så er forhol...</td>\n",
       "      <td>besøg fra arbejdstilsynet klare krav</td>\n",
       "      <td>det er ikke kun sygeplejersker, der flygter fr...</td>\n",
       "      <td>trine warrer juul</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>2021-12-06 04:55:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/sjaelland/...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[sundhedsstyrelsen, kom, torsdag, med, hård, k...</td>\n",
       "      <td>det er ikk kun sygeplejersker, der flygt fra r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>1496</td>\n",
       "      <td>detektor: talsperson erkender - har ikke tal p...</td>\n",
       "      <td>talsperson for opsigelser blandt sygeplejerske...</td>\n",
       "      <td>debatindlæg som dokumenation sundhedsøkonom: '...</td>\n",
       "      <td>- patienter ligger på gangene og dør, fordi de...</td>\n",
       "      <td>august stenbroen</td>\n",
       "      <td>Detektor</td>\n",
       "      <td>2021-12-22 19:39:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/detektor/detektor-ta...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[stop, det, offentlige, forbrug, og, sænk, ska...</td>\n",
       "      <td>- patient lig på gang og dør, fordi de ikk bli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>1497</td>\n",
       "      <td>flere sygeplejersker skifter til det private: ...</td>\n",
       "      <td>der skal gøres noget ved løn og vilkår i det o...</td>\n",
       "      <td>fik hjertebanken sygeplejerskerne siger fra ’i...</td>\n",
       "      <td>højere løn og bedre arbejdstider. det var det,...</td>\n",
       "      <td>allan nisgaard</td>\n",
       "      <td>Indland</td>\n",
       "      <td>2021-12-29 04:46:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/indland/flere-sygepl...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[der, er, mange, forsinkelser, og, fejl, i, va...</td>\n",
       "      <td>høj løn og bedr arbejdstider. det var det, som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1498</td>\n",
       "      <td>nu skal sygeplejersker og læger fra hospitaler...</td>\n",
       "      <td>i både region midtjylland og region syddanmark...</td>\n",
       "      <td>frygter længere ventelister ansætter mange</td>\n",
       "      <td>meldingen fra sundhedsmyndighederne har været ...</td>\n",
       "      <td>emil eller</td>\n",
       "      <td>Indland</td>\n",
       "      <td>2021-12-15 04:50:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/indland/nu-skal-syge...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[36, årige, kirsten, brosbøl, bliver, ny, milj...</td>\n",
       "      <td>melding fra sundhedsmyndighed har vær helt kla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>1499</td>\n",
       "      <td>'det skal være normen at være på fuldtid': men...</td>\n",
       "      <td>regionshospitalet randers kunne få timer svare...</td>\n",
       "      <td>fuldtidsstrategi enormt potentiale sygeplejers...</td>\n",
       "      <td>det var et ønske om at se sine børn noget mere...</td>\n",
       "      <td>thomas klose jensen</td>\n",
       "      <td>Østjylland</td>\n",
       "      <td>2021-12-11 05:46:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/oestjyllan...</td>\n",
       "      <td>DR</td>\n",
       "      <td>[sundhedsmyndighederne, i, usa, har, mandag, a...</td>\n",
       "      <td>det var et ønsk om at se sin børn nog mere, de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             titles  \\\n",
       "0             0              danske sygeplejersker får job i norge   \n",
       "1             1                 næsten ingen ledige sygeplejersker   \n",
       "2             5    regionsformand: jeg har ikke noget at undskylde   \n",
       "3            14             sygeplejersker vil skære i nattevagter   \n",
       "4            15           udenlandske sygeplejersker er taget hjem   \n",
       "..          ...                                                ...   \n",
       "523        1495  læger og sygeplejersker siger stop: 'kan ikke ...   \n",
       "524        1496  detektor: talsperson erkender - har ikke tal p...   \n",
       "525        1497  flere sygeplejersker skifter til det private: ...   \n",
       "526        1498  nu skal sygeplejersker og læger fra hospitaler...   \n",
       "527        1499  'det skal være normen at være på fuldtid': men...   \n",
       "\n",
       "                                            sub_header  \\\n",
       "0    krise, fyringer og ansættelsesstop får sygeple...   \n",
       "1    trods fyringsrunder i både 2010 og 2011 er arb...   \n",
       "2    steen bach nielsen forstår ikke, at sygeplejer...   \n",
       "3    risiko for at natarbejde er kræftfremkaldende ...   \n",
       "4    det er slut med sygeplejerudtryk på gebrokkent...   \n",
       "..                                                 ...   \n",
       "523  ifølge ansatte på holbæk sygehus, så er forhol...   \n",
       "524  talsperson for opsigelser blandt sygeplejerske...   \n",
       "525  der skal gøres noget ved løn og vilkår i det o...   \n",
       "526  i både region midtjylland og region syddanmark...   \n",
       "527  regionshospitalet randers kunne få timer svare...   \n",
       "\n",
       "                                                    h2  \\\n",
       "0                                        markant flere   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3           færre nattevagter fast døgnrytme er vigtig   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "523               besøg fra arbejdstilsynet klare krav   \n",
       "524  debatindlæg som dokumenation sundhedsøkonom: '...   \n",
       "525  fik hjertebanken sygeplejerskerne siger fra ’i...   \n",
       "526         frygter længere ventelister ansætter mange   \n",
       "527  fuldtidsstrategi enormt potentiale sygeplejers...   \n",
       "\n",
       "                                               content               author  \\\n",
       "0    antallet af danske sygeplejersker, der har fåe...              ritzau/   \n",
       "1    trods fyringsrunder på sygehusene i både 2010 ...      henny mortensen   \n",
       "2    der er ikke noget at undskylde eller beklage.....        jørgen hansen   \n",
       "3    dansk sygeplejeråd, der repræsenterer landets ...               ritzau   \n",
       "4    det er slut med sygeplejerudtryk på gebrokkent...  mikkel from nielsen   \n",
       "..                                                 ...                  ...   \n",
       "523  det er ikke kun sygeplejersker, der flygter fr...    trine warrer juul   \n",
       "524  - patienter ligger på gangene og dør, fordi de...     august stenbroen   \n",
       "525  højere løn og bedre arbejdstider. det var det,...       allan nisgaard   \n",
       "526  meldingen fra sundhedsmyndighederne har været ...           emil eller   \n",
       "527  det var et ønske om at se sine børn noget mere...  thomas klose jensen   \n",
       "\n",
       "             tag                       date  \\\n",
       "0          Penge  2012-01-19 13:27:00+00:00   \n",
       "1       Sjælland  2012-01-28 07:42:00+00:00   \n",
       "2       Sjælland  2012-01-24 15:39:00+00:00   \n",
       "3        Indland  2012-02-21 10:48:00+00:00   \n",
       "4    Nordjylland  2012-02-27 15:26:00+00:00   \n",
       "..           ...                        ...   \n",
       "523     Sjælland  2021-12-06 04:55:00+00:00   \n",
       "524     Detektor  2021-12-22 19:39:00+00:00   \n",
       "525      Indland  2021-12-29 04:46:00+00:00   \n",
       "526      Indland  2021-12-15 04:50:00+00:00   \n",
       "527   Østjylland  2021-12-11 05:46:00+00:00   \n",
       "\n",
       "                                                  link source  \\\n",
       "0    https://www.dr.dk/nyheder/penge/danske-sygeple...     DR   \n",
       "1    https://www.dr.dk/nyheder/regionale/sjaelland/...     DR   \n",
       "2    https://www.dr.dk/nyheder/regionale/sjaelland/...     DR   \n",
       "3    https://www.dr.dk/nyheder/indland/sygeplejersk...     DR   \n",
       "4    https://www.dr.dk/nyheder/regionale/nordjyllan...     DR   \n",
       "..                                                 ...    ...   \n",
       "523  https://www.dr.dk/nyheder/regionale/sjaelland/...     DR   \n",
       "524  https://www.dr.dk/nyheder/detektor/detektor-ta...     DR   \n",
       "525  https://www.dr.dk/nyheder/indland/flere-sygepl...     DR   \n",
       "526  https://www.dr.dk/nyheder/indland/nu-skal-syge...     DR   \n",
       "527  https://www.dr.dk/nyheder/regionale/oestjyllan...     DR   \n",
       "\n",
       "                                             tokenized  \\\n",
       "0    [mens, nyuddannede, danske, sygeplejersker, ha...   \n",
       "1    [antallet, af, danske, sygeplejersker, der, ha...   \n",
       "2    [en, bevæbnet, mand, har, skudt, og, dræbt, sy...   \n",
       "3    [hvert, år, dør, hundredvis, af, patienter, fo...   \n",
       "4    [sygeplejersker, lærere, politifolk, og, unge,...   \n",
       "..                                                 ...   \n",
       "523  [sundhedsstyrelsen, kom, torsdag, med, hård, k...   \n",
       "524  [stop, det, offentlige, forbrug, og, sænk, ska...   \n",
       "525  [der, er, mange, forsinkelser, og, fejl, i, va...   \n",
       "526  [36, årige, kirsten, brosbøl, bliver, ny, milj...   \n",
       "527  [sundhedsmyndighederne, i, usa, har, mandag, a...   \n",
       "\n",
       "                                                 stems  \n",
       "0    antal af dansk sygeplejersker, der har fået au...  \n",
       "1    trod fyringsrund på sygehus i båd 2010 og 2011...  \n",
       "2    der er ikk nog at undskyld ell beklage... form...  \n",
       "3    dansk sygeplejeråd, der repræsent land omkring...  \n",
       "4    det er slut med sygeplejerudtryk på gebrokkent...  \n",
       "..                                                 ...  \n",
       "523  det er ikk kun sygeplejersker, der flygt fra r...  \n",
       "524  - patient lig på gang og dør, fordi de ikk bli...  \n",
       "525  høj løn og bedr arbejdstider. det var det, som...  \n",
       "526  melding fra sundhedsmyndighed har vær helt kla...  \n",
       "527  det var et ønsk om at se sin børn nog mere, de...  \n",
       "\n",
       "[528 rows x 12 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a539c10e-1aab-4d3c-aadb-1d38f6c51111",
   "metadata": {},
   "outputs": [],
   "source": [
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb62ab63-bec7-46a7-8f06-30de1121b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer() #Store the class in 'count' to ease coding\n",
    "count_array = dr_2['stems'] #Take the first two reviews and store them in an array\n",
    "bag = count.fit_transform(count_array) #fit_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e94caa-0dd4-41a2-bfd6-ec7f2e0049a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9cc62193-08c8-4d6d-9461-042c8ee33a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>001</th>\n",
       "      <th>007</th>\n",
       "      <th>015</th>\n",
       "      <th>02</th>\n",
       "      <th>030</th>\n",
       "      <th>031</th>\n",
       "      <th>04</th>\n",
       "      <th>042</th>\n",
       "      <th>...</th>\n",
       "      <th>østjysk</th>\n",
       "      <th>østkyst</th>\n",
       "      <th>østr</th>\n",
       "      <th>øve</th>\n",
       "      <th>øvels</th>\n",
       "      <th>øvelse</th>\n",
       "      <th>øver</th>\n",
       "      <th>øverst</th>\n",
       "      <th>øvet</th>\n",
       "      <th>øvr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528 rows × 12915 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00  000  001  007  015  02  030  031  04  042  ...  østjysk  østkyst  \\\n",
       "0     0    0    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "1     0    0    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "2     0    0    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "3     0    1    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "4     0    0    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "..   ..  ...  ...  ...  ...  ..  ...  ...  ..  ...  ...      ...      ...   \n",
       "523   0    0    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "524   0    0    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "525   0    1    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "526   0    0    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "527   0    0    0    0    0   0    0    0   0    0  ...        0        0   \n",
       "\n",
       "     østr  øve  øvels  øvelse  øver  øverst  øvet  øvr  \n",
       "0       0    0      0       0     0       0     0    0  \n",
       "1       0    0      0       0     0       0     0    0  \n",
       "2       0    0      0       0     0       0     0    0  \n",
       "3       0    0      0       0     0       0     0    0  \n",
       "4       0    0      0       0     0       0     0    0  \n",
       "..    ...  ...    ...     ...   ...     ...   ...  ...  \n",
       "523     0    0      0       0     0       0     0    0  \n",
       "524     0    0      0       0     0       0     0    0  \n",
       "525     0    0      0       0     0       0     0    0  \n",
       "526     0    0      0       0     0       0     0    0  \n",
       "527     0    0      0       0     0       0     0    0  \n",
       "\n",
       "[528 rows x 12915 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = bag.toarray() #Make the bag to an array\n",
    "matrix = pd.DataFrame(data=array,columns = count.get_feature_names_out()) #Input the bag and the words into a dataframe\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d29cc14-8c2f-49dd-84c7-ab6398524ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "at                 8419\n",
       "er                 6830\n",
       "det                6463\n",
       "og                 5902\n",
       "der                4785\n",
       "                   ... \n",
       "gastromedicinsk       1\n",
       "gastromé              1\n",
       "posttraumatisk        1\n",
       "postkas               1\n",
       "loyalit               1\n",
       "Length: 12915, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sum = matrix.sum().transpose()\n",
    "matrix_sum.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ae6a5-60d7-4d4a-b7dd-f60f7ce03477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5134f61e-9289-4313-9753-4196062a23d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (503) does not match length of index (528)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dr_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     dr_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstemmed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m[stemmer\u001b[38;5;241m.\u001b[39mstem(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m i]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3832\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3835\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3836\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3838\u001b[0m     ):\n\u001b[1;32m   3839\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3840\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4535\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (503) does not match length of index (528)"
     ]
    }
   ],
   "source": [
    "for i in dr_2['tokenized']:\n",
    "    dr_2['stemmed']=[stemmer.stem(word) for word in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616fd10-6cc1-46ae-b095-cfe12ecff8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_stemmed_with_num = [stemmer.stem(row['tokenized']) for word in row['tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d1d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tokenizer function\n",
    "def tokenizer(df):\n",
    "    df_tokenslist = []\n",
    "    for document in tqdm.tqdm(df['content']):\n",
    "        tokens = nltk.tokenize.word_tokenize(document, language = 'danish')\n",
    "        df_tokenslist.append(tokens)\n",
    "    df_tokens = list(itertools.chain(*df_tokenslist))\n",
    "    return df_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea62f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 528/528 [00:00<00:00, 818.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3607/3607 [00:06<00:00, 549.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2562567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 296/296 [00:16<00:00, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7843399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dr_2_tokens = tokenizer(dr_2)\n",
    "print(len(dr_2_tokens))\n",
    "tv2_2_tokens = tokenizer(tv2_2)\n",
    "print(len(tv2_2_tokens))\n",
    "ft_2_tokens = tokenizer(ft_2)\n",
    "print(len(ft_2_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41f07a",
   "metadata": {},
   "source": [
    "## Remove stopwords and create word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3391b31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/oliver/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get stopwords list\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('danish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b026bc",
   "metadata": {},
   "source": [
    "### Tokenized content for three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e06c0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords from token-list\n",
    "dr_nostop = [word for word in dr_2_tokens if not word in stopwords]\n",
    "tv2_nostop = [word for word in tv2_2_tokens if not word in stopwords]\n",
    "ft_nostop = [word for word in ft_2_tokens if not word in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a3785",
   "metadata": {},
   "source": [
    "### Create set of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c5b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_complete = dr_nostop + tv2_nostop + ft_nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75a6ad68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5356096"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c834bfe6",
   "metadata": {},
   "source": [
    "The total number of words across our three datasets is 5356096."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76b0ac",
   "metadata": {},
   "source": [
    "Our unique wordset contains 115189 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc3df5",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c43818f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"danish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac56817",
   "metadata": {},
   "outputs": [],
   "source": [
    "[stemmer.stem(word) for word in ['tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cbf7c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75802"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete duplicates\n",
    "wordlist_stemmed_with_num = list(set(wordlist_stemmed_with_num))\n",
    "len(wordlist_stemmed_with_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dacd1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers\n",
    "wordlist_stemmed = [word for word in wordlist_stemmed_with_num if not word.isdigit()]            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d0369",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b6779e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Danish lemmatizer\n",
    "lem = lemmy.load(\"da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "46ccd7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_lem = [lem.lemmatize(\"\", word) for word in wordset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list instead of list of list\n",
    "wordlist_lem = [word for sublist in wordlist_lem for word in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a46d03ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist_lem_2 = wordlist_lem_2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da038f",
   "metadata": {},
   "source": [
    "Comment: The lemmatization returns a list of lists that also contains more than two words which could lead to problems.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58379d37",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8976aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_matrix_sum = pd.read_csv('dr_matix_sum.csv').set_index('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caee7e81-5a3c-471c-853a-33e414ef7596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>øvels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>øver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>øverst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>øvet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>øvr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9574 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0\n",
       "0             \n",
       "2           00\n",
       "273        000\n",
       "1          001\n",
       "1          007\n",
       "1          015\n",
       "..         ...\n",
       "2        øvels\n",
       "4         øver\n",
       "10      øverst\n",
       "2         øvet\n",
       "33         øvr\n",
       "\n",
       "[9574 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_matrix_sum.rename("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a7921-e18e-4849-bbf2-12fbe54a7683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
