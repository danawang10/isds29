{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e58d9fe",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5077bc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\jgb569\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\jgb569\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\jgb569\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jgb569\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jgb569\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jgb569\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import lemmy # For lemmatization\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a4c70",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "222ad44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_sygeplej2x = pd.read_csv('ft_sygeplej2x.csv')\n",
    "dr_sygeplej2x = pd.read_csv('dr_sygeplej2x.csv')\n",
    "tv2_sygeplej2x = pd.read_csv('tv2_sygeplej2x.csv')\n",
    "\n",
    "ft_2 = ft_sygeplej2x.copy() \n",
    "dr_2 = dr_sygeplej2x.copy() \n",
    "tv2_2 = tv2_sygeplej2x.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12faaf",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048bcc9e",
   "metadata": {},
   "source": [
    "## Remove non-alphanumerical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1acc8f80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgb569\\AppData\\Local\\Temp/ipykernel_6844/1145022020.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['content'] = df['content'].str.replace(r'\\W', ' ')\\\n"
     ]
    }
   ],
   "source": [
    "for df in [ft_2, dr_2, tv2_2]:\n",
    "    df['content'] = df['content'].str.replace(r'\\W', ' ')\\\n",
    "                                 .str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251e3b8",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dcf169b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tv2_2[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6bd8ae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/danish.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\jgb569/nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6844/3522017243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/danish.pickle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    877\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/danish.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\jgb569/nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/danish.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "175e0605",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/danish.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\jgb569/nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6844/2190953297.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mft_2_tokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'danish'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     return [\n\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    877\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/danish.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\jgb569/nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\jgb569\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "ft_2_tokens = [] \n",
    "\n",
    "for document in sample['content']:\n",
    "    ft_2_tokens.append(nltk.tokenize.word_tokenize(document, language = 'danish'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0319c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [ft_2, dr_2, tv2_2]:\n",
    "     = df['content']\n",
    "    for row in df['content_tokens']:\n",
    "        df['content_stop'] = df['content_stop'].str.replace(stopwords, ' ')\n",
    "\n",
    "df_tokens = nltk.tokenize.word_tokenize('content')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9dbadd",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94fa8454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jgb569\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get stopwords list\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('danish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9503ebea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f6f6f99",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (Temp/ipykernel_6844/1308068437.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\jgb569\\AppData\\Local\\Temp/ipykernel_6844/1308068437.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    df['content_stop'] = df['content_stop'].str.replace(f'{ stopword }, ' ')\u001b[0m\n\u001b[1;37m                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords from datasets\n",
    "for df in [ft_2, dr_2, tv2_2]:\n",
    "    df['content_stop'] = df['content']\n",
    "    for stopword in stopwords:\n",
    "        df['content_stop'] = df['content_stop'].str.replace(stopwords, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "986588a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 296/296 [00:04<00:00, 65.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 528/528 [00:00<00:00, 3416.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3607/3607 [00:01<00:00, 2286.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords from datasets\n",
    "for df in [ft_2, dr_2, tv2_2]:\n",
    "    for row in tqdm.tqdm(df['content']):\n",
    "        for stopword in stopwords:\n",
    "            row = row.replace(stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbad1d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 296/296 [00:10<00:00, 28.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 528/528 [00:00<00:00, 2087.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3607/3607 [00:03<00:00, 1189.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords from datasets\n",
    "for df in [ft_2, dr_2, tv2_2]:\n",
    "    for row in tqdm.tqdm(df['content']):\n",
    "        row = ''.join(stopword for stopword in row.split() if stopword not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1dea61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2dbb130e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>titles</th>\n",
       "      <th>sub_header</th>\n",
       "      <th>h2</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>tag</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>content_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>danske sygeplejersker får job i norge</td>\n",
       "      <td>krise, fyringer og ansættelsesstop får sygeple...</td>\n",
       "      <td>markant flere</td>\n",
       "      <td>antallet af danske sygeplejersker der har fået...</td>\n",
       "      <td>ritzau/</td>\n",
       "      <td>Penge</td>\n",
       "      <td>2012-01-19 13:27:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/penge/danske-sygeple...</td>\n",
       "      <td>DR</td>\n",
       "      <td>antall  nske sygeplejsk d  få autorson  norge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>næsten ingen ledige sygeplejersker</td>\n",
       "      <td>trods fyringsrunder i både 2010 og 2011 er arb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trods fyringsrunder på sygehusene i både 2010 ...</td>\n",
       "      <td>henny mortensen</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>2012-01-28 07:42:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/sjaelland/...</td>\n",
       "      <td>DR</td>\n",
       "      <td>trods fyrngsrund  sygehuse  bå 2010  2011  læg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>regionsformand: jeg har ikke noget at undskylde</td>\n",
       "      <td>steen bach nielsen forstår ikke, at sygeplejer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>der er ikke noget at undskylde eller beklage f...</td>\n",
       "      <td>jørgen hansen</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>2012-01-24 15:39:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/sjaelland/...</td>\n",
       "      <td>DR</td>\n",
       "      <td>d  kke n  undskyl ell beklage d  regon sjællan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>sygeplejersker vil skære i nattevagter</td>\n",
       "      <td>risiko for at natarbejde er kræftfremkaldende ...</td>\n",
       "      <td>færre nattevagter fast døgnrytme er vigtig</td>\n",
       "      <td>dansk sygeplejeråd der repræsenterer landets o...</td>\n",
       "      <td>ritzau</td>\n",
       "      <td>Indland</td>\n",
       "      <td>2012-02-21 10:48:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/indland/sygeplejersk...</td>\n",
       "      <td>DR</td>\n",
       "      <td>nsk sygeplejåd d repræst lans krng 70 000 syge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>udenlandske sygeplejersker er taget hjem</td>\n",
       "      <td>det er slut med sygeplejerudtryk på gebrokkent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>det er slut med sygeplejerudtryk på gebrokkent...</td>\n",
       "      <td>mikkel from nielsen</td>\n",
       "      <td>Nordjylland</td>\n",
       "      <td>2012-02-27 15:26:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/nordjyllan...</td>\n",
       "      <td>DR</td>\n",
       "      <td>slut  sygeplejtryk  gebrokkt nsk   nordjyske...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>1495</td>\n",
       "      <td>læger og sygeplejersker siger stop: 'kan ikke ...</td>\n",
       "      <td>ifølge ansatte på holbæk sygehus, så er forhol...</td>\n",
       "      <td>besøg fra arbejdstilsynet klare krav</td>\n",
       "      <td>det er ikke kun sygeplejersker der flygter fra...</td>\n",
       "      <td>trine warrer juul</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>2021-12-06 04:55:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/sjaelland/...</td>\n",
       "      <td>DR</td>\n",
       "      <td>kke kun sygeplejsk d flygt  regon sjællands ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>1496</td>\n",
       "      <td>detektor: talsperson erkender - har ikke tal p...</td>\n",
       "      <td>talsperson for opsigelser blandt sygeplejerske...</td>\n",
       "      <td>debatindlæg som dokumenation sundhedsøkonom: '...</td>\n",
       "      <td>patienter ligger på gangene og dør fordi de i...</td>\n",
       "      <td>august stenbroen</td>\n",
       "      <td>Detektor</td>\n",
       "      <td>2021-12-22 19:39:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/detektor/detektor-ta...</td>\n",
       "      <td>DR</td>\n",
       "      <td>pt lgg  gange  dør d  kke blv tls sag luca pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>1497</td>\n",
       "      <td>flere sygeplejersker skifter til det private: ...</td>\n",
       "      <td>der skal gøres noget ved løn og vilkår i det o...</td>\n",
       "      <td>fik hjertebanken sygeplejerskerne siger fra ’i...</td>\n",
       "      <td>højere løn og bedre arbejdstider det var det s...</td>\n",
       "      <td>allan nisgaard</td>\n",
       "      <td>Indland</td>\n",
       "      <td>2021-12-29 04:46:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/indland/flere-sygepl...</td>\n",
       "      <td>DR</td>\n",
       "      <td>høje løn  bedre arbejdstd     fk sygeplejskevk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1498</td>\n",
       "      <td>nu skal sygeplejersker og læger fra hospitaler...</td>\n",
       "      <td>i både region midtjylland og region syddanmark...</td>\n",
       "      <td>frygter længere ventelister ansætter mange</td>\n",
       "      <td>meldingen fra sundhedsmyndighederne har været ...</td>\n",
       "      <td>emil eller</td>\n",
       "      <td>Indland</td>\n",
       "      <td>2021-12-15 04:50:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/indland/nu-skal-syge...</td>\n",
       "      <td>DR</td>\n",
       "      <td>meldng  sundhedsmyndghedne  vær helt klar d  r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>1499</td>\n",
       "      <td>'det skal være normen at være på fuldtid': men...</td>\n",
       "      <td>regionshospitalet randers kunne få timer svare...</td>\n",
       "      <td>fuldtidsstrategi enormt potentiale sygeplejers...</td>\n",
       "      <td>det var et ønske om at se sine børn noget mere...</td>\n",
       "      <td>thomas klose jensen</td>\n",
       "      <td>Østjylland</td>\n",
       "      <td>2021-12-11 05:46:00+00:00</td>\n",
       "      <td>https://www.dr.dk/nyheder/regionale/oestjyllan...</td>\n",
       "      <td>DR</td>\n",
       "      <td>ønske   se sne børn n me d rnlgt fk male se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             titles  \\\n",
       "0             0              danske sygeplejersker får job i norge   \n",
       "1             1                 næsten ingen ledige sygeplejersker   \n",
       "2             5    regionsformand: jeg har ikke noget at undskylde   \n",
       "3            14             sygeplejersker vil skære i nattevagter   \n",
       "4            15           udenlandske sygeplejersker er taget hjem   \n",
       "..          ...                                                ...   \n",
       "523        1495  læger og sygeplejersker siger stop: 'kan ikke ...   \n",
       "524        1496  detektor: talsperson erkender - har ikke tal p...   \n",
       "525        1497  flere sygeplejersker skifter til det private: ...   \n",
       "526        1498  nu skal sygeplejersker og læger fra hospitaler...   \n",
       "527        1499  'det skal være normen at være på fuldtid': men...   \n",
       "\n",
       "                                            sub_header  \\\n",
       "0    krise, fyringer og ansættelsesstop får sygeple...   \n",
       "1    trods fyringsrunder i både 2010 og 2011 er arb...   \n",
       "2    steen bach nielsen forstår ikke, at sygeplejer...   \n",
       "3    risiko for at natarbejde er kræftfremkaldende ...   \n",
       "4    det er slut med sygeplejerudtryk på gebrokkent...   \n",
       "..                                                 ...   \n",
       "523  ifølge ansatte på holbæk sygehus, så er forhol...   \n",
       "524  talsperson for opsigelser blandt sygeplejerske...   \n",
       "525  der skal gøres noget ved løn og vilkår i det o...   \n",
       "526  i både region midtjylland og region syddanmark...   \n",
       "527  regionshospitalet randers kunne få timer svare...   \n",
       "\n",
       "                                                    h2  \\\n",
       "0                                        markant flere   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3           færre nattevagter fast døgnrytme er vigtig   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "523               besøg fra arbejdstilsynet klare krav   \n",
       "524  debatindlæg som dokumenation sundhedsøkonom: '...   \n",
       "525  fik hjertebanken sygeplejerskerne siger fra ’i...   \n",
       "526         frygter længere ventelister ansætter mange   \n",
       "527  fuldtidsstrategi enormt potentiale sygeplejers...   \n",
       "\n",
       "                                               content               author  \\\n",
       "0    antallet af danske sygeplejersker der har fået...              ritzau/   \n",
       "1    trods fyringsrunder på sygehusene i både 2010 ...      henny mortensen   \n",
       "2    der er ikke noget at undskylde eller beklage f...        jørgen hansen   \n",
       "3    dansk sygeplejeråd der repræsenterer landets o...               ritzau   \n",
       "4    det er slut med sygeplejerudtryk på gebrokkent...  mikkel from nielsen   \n",
       "..                                                 ...                  ...   \n",
       "523  det er ikke kun sygeplejersker der flygter fra...    trine warrer juul   \n",
       "524   patienter ligger på gangene og dør fordi de i...     august stenbroen   \n",
       "525  højere løn og bedre arbejdstider det var det s...       allan nisgaard   \n",
       "526  meldingen fra sundhedsmyndighederne har været ...           emil eller   \n",
       "527  det var et ønske om at se sine børn noget mere...  thomas klose jensen   \n",
       "\n",
       "             tag                       date  \\\n",
       "0          Penge  2012-01-19 13:27:00+00:00   \n",
       "1       Sjælland  2012-01-28 07:42:00+00:00   \n",
       "2       Sjælland  2012-01-24 15:39:00+00:00   \n",
       "3        Indland  2012-02-21 10:48:00+00:00   \n",
       "4    Nordjylland  2012-02-27 15:26:00+00:00   \n",
       "..           ...                        ...   \n",
       "523     Sjælland  2021-12-06 04:55:00+00:00   \n",
       "524     Detektor  2021-12-22 19:39:00+00:00   \n",
       "525      Indland  2021-12-29 04:46:00+00:00   \n",
       "526      Indland  2021-12-15 04:50:00+00:00   \n",
       "527   Østjylland  2021-12-11 05:46:00+00:00   \n",
       "\n",
       "                                                  link source  \\\n",
       "0    https://www.dr.dk/nyheder/penge/danske-sygeple...     DR   \n",
       "1    https://www.dr.dk/nyheder/regionale/sjaelland/...     DR   \n",
       "2    https://www.dr.dk/nyheder/regionale/sjaelland/...     DR   \n",
       "3    https://www.dr.dk/nyheder/indland/sygeplejersk...     DR   \n",
       "4    https://www.dr.dk/nyheder/regionale/nordjyllan...     DR   \n",
       "..                                                 ...    ...   \n",
       "523  https://www.dr.dk/nyheder/regionale/sjaelland/...     DR   \n",
       "524  https://www.dr.dk/nyheder/detektor/detektor-ta...     DR   \n",
       "525  https://www.dr.dk/nyheder/indland/flere-sygepl...     DR   \n",
       "526  https://www.dr.dk/nyheder/indland/nu-skal-syge...     DR   \n",
       "527  https://www.dr.dk/nyheder/regionale/oestjyllan...     DR   \n",
       "\n",
       "                                          content_stop  \n",
       "0    antall  nske sygeplejsk d  få autorson  norge ...  \n",
       "1    trods fyrngsrund  sygehuse  bå 2010  2011  læg...  \n",
       "2    d  kke n  undskyl ell beklage d  regon sjællan...  \n",
       "3    nsk sygeplejåd d repræst lans krng 70 000 syge...  \n",
       "4      slut  sygeplejtryk  gebrokkt nsk   nordjyske...  \n",
       "..                                                 ...  \n",
       "523    kke kun sygeplejsk d flygt  regon sjællands ...  \n",
       "524   pt lgg  gange  dør d  kke blv tls sag luca pr...  \n",
       "525  høje løn  bedre arbejdstd     fk sygeplejskevk...  \n",
       "526  meldng  sundhedsmyndghedne  vær helt klar d  r...  \n",
       "527     ønske   se sne børn n me d rnlgt fk male se...  \n",
       "\n",
       "[528 rows x 11 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eba470",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fdf6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Danish lemmatizer\n",
    "lem = lemmy.load(\"da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c99182a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sygeplejerske']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [ft_2, dr_2, tv2_2]:\n",
    "    df['content_lem'] = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77c544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lemmyNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading lemmy-2.1.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: lemmy\n",
      "Successfully installed lemmy-2.1.0\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
