{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc7f927-e3c6-49aa-b879-fe4e74ddfec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84bdce84-2161-4935-ba34-613131b4cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "links=pd.read_csv(\"list_of_articles.csv\", index_col=False).reset_index(drop=True)\n",
    "links.columns=(\"b\", \"a\")\n",
    "links=links.drop(columns=[\"b\"])\n",
    "links_list=links[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6006b854-884f-4716-b899-8db6b8005cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\n"
     ]
    }
   ],
   "source": [
    "titles_list=[]\n",
    "h2_list=[]\n",
    "date_list=[]\n",
    "content_list=[]\n",
    "author_list=[]\n",
    "sub_head_list=[]\n",
    "tag_list=[]\n",
    "\n",
    "#  Define start and end of article loop\n",
    "start=0 \n",
    "end=10\n",
    "\n",
    "\n",
    "for u in tqdm.tqdm(links_list[start: end]) :\n",
    "    re=requests.get(u, headers={\"Name\" : \"Oliver Fredborg Smietana\" , \"email\": \"kph383@alumni.ku.dk\", \"Purpose\": \"exam project for Copenhagen uni Course\" })\n",
    "    soup=BeautifulSoup(re.content, \"lxml\")\n",
    "    try:\n",
    "        title=soup.find(\"h1\", class_=\"tc_heading tc_heading--2\")\n",
    "        titles_list.append(title.text.strip())\n",
    "    except:\n",
    "        titles_list.append(\"\")\n",
    "\n",
    "    try:\n",
    "        date=soup.find(\"time\", class_=\"tc_timestamp\")['datetime']\n",
    "        date_list.append(date)\n",
    "    except:\n",
    "        date_list.append(\"\")\n",
    "\n",
    "    try:\n",
    "        h2=soup.find_all(\"h2\", class_=\"tc_heading tc_heading--2\")\n",
    "        h2_i_list=[]\n",
    "        for i in h2:\n",
    "            h2_i=i.get_text()\n",
    "            h2_i_list.append(h2_i)\n",
    "        h2_str=\" \".join(h2_i_list)\n",
    "        h2_list.append(h2_str)\n",
    "    except:\n",
    "        h2_list.append(\"\")\n",
    "\n",
    "    try:\n",
    "        sub_head=soup.find(\"p\", class_=\"tc_page__body__standfirst\")\n",
    "        sub_head_list.append(sub_head.text.strip())\n",
    "    except:\n",
    "        sub_head_list.append(\"\")\n",
    "\n",
    "    try:\n",
    "        author=soup.find(\"span\", class_=\"tc_byline__author__text\")\n",
    "        author_list.append(author.text.strip())\n",
    "    except:\n",
    "         author_list.append(\"\")\n",
    "\n",
    "    try:\n",
    "        content_i_list=[]\n",
    "        content_i=soup.find(\"div\", class_=\"tc_richcontent\").find_all(\"p\")\n",
    "        for i in content_i:\n",
    "            content_i_list.append(i.text.strip())\n",
    "        content_str=\" \".join(content_i_list)\n",
    "        content_list.append(content_str)\n",
    "    except:\n",
    "        content_list.append(\"\")\n",
    "\n",
    "    try:\n",
    "        tag=soup.find(\"a\", class_=\"tc_label tc_label--color-base-red\")\n",
    "        tag_list.append(tag.text.strip())\n",
    "    except:\n",
    "        tag_list.append(\"\")\n",
    "\n",
    "    time.sleep(0.25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "836b95cb-78a5-4508-998f-5ef92d6db75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tv2_articles=pd.DataFrame([titles_list, sub_head_list, h2_list, content_list, author_list, tag_list, date_list, links_list[start:end]]).transpose()\n",
    "tv2_articles.columns=[\"titles\", \"sub_header\", \"h2\", \"content\", \"author\", \"tag\", \"date\", \"link\"]\n",
    "tv2_articles[\"tv2\"]=\"tv2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f2b9ab5-246e-4006-aaa3-502aabe29af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv2_articles.to_csv(\"articles_tv2_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e488fe06-e628-4857-a9bc-52ead6bffaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv2_articles=pd.read_csv(\"articles_tv2.csv\", index_col=False).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e434f48-309b-4b23-bf80-2fa81f8f0089",
   "metadata": {},
   "source": [
    "We scraped the articles in six chunks and to put them back together we used this code\n",
    "```\n",
    "tv2_articles2=pd.read_csv(\"articles_tv2_section_2.csv\", index_col=False).reset_index(drop=True)\n",
    "\n",
    "articles_tv2=pd.concat([tv2_articles1, tv2_articles2], axis=0).reset_index(drop=True)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
